"""
ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
ì‘ê¸‰ ìƒí™© vs ì¼ë°˜ ì§ˆë¬¸ ì„±ëŠ¥ ë¹„êµ ë° ìƒì„¸ ë¶„ì„
"""

import time
import statistics
from typing import List, Dict, Any
from dataclasses import dataclass

from src.agents.vehicle_agent import VehicleManualAgent
from src.utils.emergency_detector import EmergencyDetector
from src.config.settings import DEFAULT_PDF_PATH


@dataclass
class BenchmarkResult:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    query_type: str
    queries: List[str]
    response_times: List[float]
    avg_time: float
    min_time: float
    max_time: float
    std_dev: float
    total_chars: int
    avg_chars: int


class PerformanceBenchmark:
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ë²¤ì¹˜ë§ˆí¬ ì´ˆê¸°í™”"""
        print("ğŸ”§ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        self.agent = VehicleManualAgent(str(DEFAULT_PDF_PATH))
        self.detector = EmergencyDetector()
        print("âœ… SubGraph ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì •ì˜
        self.emergency_queries = [
            # CRITICAL ìˆ˜ì¤€
            "ì°¨ì—ì„œ íƒ€ëŠ” ëƒ„ìƒˆê°€ ë‚˜ëŠ”ë° í™”ì¬ ìœ„í—˜ì´ ìˆì„ ë•Œ ì–´ë–»ê²Œ í•´ì•¼ í•´ìš”?",
            "ì—”ì§„ì—ì„œ ì—°ê¸°ê°€ ë‚˜ê³  ìˆì–´ìš”! ì¦‰ì‹œ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
            "ì°¨ëŸ‰ì— ë¶ˆì´ ë‚¬ëŠ”ë° ì–´ë–»ê²Œ ëŒ€í”¼í•´ì•¼ í•´ìš”?",
            
            # HIGH ìˆ˜ì¤€
            "ë¸Œë ˆì´í¬ë¥¼ ë°Ÿì•„ë„ ì°¨ê°€ ë©ˆì¶”ì§€ ì•Šì•„ìš”! ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
            "ì£¼í–‰ ì¤‘ í•¸ë“¤ì´ ê°‘ìê¸° ëŒì•„ê°€ì§€ ì•ŠëŠ”ë° ì‘ê¸‰ ëŒ€ì²˜ ë°©ë²•ì€?",
            "ì—”ì§„ì´ ê°‘ìê¸° ì •ì§€í–ˆëŠ”ë° ì¦‰ì‹œ í•´ì•¼ í•  ì¡°ì¹˜ëŠ”?",
            
            # MEDIUM ìˆ˜ì¤€
            "íƒ€ì´ì–´ê°€ í‘í¬ ë‚¬ëŠ”ë° ì•ˆì „í•˜ê²Œ ì •ì°¨í•˜ëŠ” ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”",
            "ì—”ì§„ ê³¼ì—´ ê²½ê³ ë“±ì´ ì¼œì¡ŒëŠ”ë° ì–´ë–»ê²Œ í•´ì•¼ í•´ìš”?",
            "ì™€ì´í¼ê°€ ê³ ì¥ë‚˜ì„œ ì•ì´ ì•ˆ ë³´ì´ëŠ”ë° ëŒ€ì²˜ë²•ì€?"
        ]
        
        self.normal_queries = [
            # ê¸°ë³¸ ì •ë³´ ë¬¸ì˜
            "íƒ€ì´ì–´ ê³µê¸°ì••ì€ ì–¼ë§ˆë¡œ ë§ì¶°ì•¼ í•˜ë‚˜ìš”?",
            "ì—”ì§„ ì˜¤ì¼ êµì²´ ì£¼ê¸°ëŠ” ì–¸ì œì¸ê°€ìš”?",
            "XC60ì˜ ì—°ë£Œ íƒ±í¬ ìš©ëŸ‰ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            
            # ì‚¬ìš©ë²• ë¬¸ì˜
            "í›„ë°© ì¹´ë©”ë¼ ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ë¸”ë£¨íˆ¬ìŠ¤ ì—°ê²° ë°©ë²•ì´ ê¶ê¸ˆí•´ìš”",
            "ì—ì–´ì»¨ í•„í„° êµì²´ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
            
            # ê¸°ëŠ¥ ë¬¸ì˜
            "í¬ë£¨ì¦ˆ ì»¨íŠ¸ë¡¤ ì„¤ì • ë°©ë²•ì€?",
            "ì‹œíŠ¸ íˆí„° ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ì£¼ì°¨ ë³´ì¡° ì‹œìŠ¤í…œ ì‚¬ìš©ë²•ì€?"
        ]
    
    def run_benchmark(self, queries: List[str], query_type: str, warmup: bool = True) -> BenchmarkResult:
        """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print(f"\nğŸ§ª {query_type} ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ ({len(queries)}ê°œ ì¿¼ë¦¬)")
        print("-" * 50)
        
        # ì›œì—… (ì²« ë²ˆì§¸ ì¿¼ë¦¬ë¡œ ì‹œìŠ¤í…œ ì¤€ë¹„)
        if warmup and queries:
            print("ğŸ”¥ ì›œì—… ì¤‘...")
            self.agent.query(queries[0])
            print("âœ… ì›œì—… ì™„ë£Œ")
        
        response_times = []
        total_chars = 0
        
        for i, query in enumerate(queries, 1):
            print(f"[{i}/{len(queries)}] {query[:50]}...")
            
            start_time = time.time()
            answer = self.agent.query(query)
            elapsed_time = time.time() - start_time
            
            response_times.append(elapsed_time)
            total_chars += len(answer)
            
            print(f"  â±ï¸  {elapsed_time:.2f}ì´ˆ, ğŸ“ {len(answer)}ì")
        
        # í†µê³„ ê³„ì‚°
        avg_time = statistics.mean(response_times)
        min_time = min(response_times)
        max_time = max(response_times)
        std_dev = statistics.stdev(response_times) if len(response_times) > 1 else 0
        avg_chars = total_chars // len(queries)
        
        return BenchmarkResult(
            query_type=query_type,
            queries=queries,
            response_times=response_times,
            avg_time=avg_time,
            min_time=min_time,
            max_time=max_time,
            std_dev=std_dev,
            total_chars=total_chars,
            avg_chars=avg_chars
        )
    
    def analyze_emergency_detection(self):
        """ì‘ê¸‰ ìƒí™© ê°ì§€ ë¶„ì„"""
        print("\nğŸ” ì‘ê¸‰ ìƒí™© ê°ì§€ ë¶„ì„")
        print("=" * 60)
        
        detection_results = {
            "CRITICAL": [],
            "HIGH": [],
            "MEDIUM": [],
            "LOW": [],
            "NORMAL": []
        }
        
        all_queries = self.emergency_queries + self.normal_queries
        
        for query in all_queries:
            result = self.detector.detect_emergency(query)
            level = result["priority_level"]
            detection_results[level].append({
                "query": query[:50] + "..." if len(query) > 50 else query,
                "score": result["total_score"],
                "is_emergency": result["is_emergency"]
            })
        
        # ê²°ê³¼ ì¶œë ¥
        for level, results in detection_results.items():
            if results:
                print(f"\nğŸš¨ {level} ìˆ˜ì¤€ ({len(results)}ê°œ)")
                for result in results:
                    status = "ğŸš¨" if result["is_emergency"] else "ğŸ“"
                    print(f"  {status} {result['query']} (ì ìˆ˜: {result['score']})")
        
        return detection_results
    
    def compare_performance(self, emergency_result: BenchmarkResult, normal_result: BenchmarkResult):
        """ì„±ëŠ¥ ë¹„êµ ë¶„ì„"""
        print("\nğŸ“Š ì„±ëŠ¥ ë¹„êµ ë¶„ì„")
        print("=" * 60)
        
        # ê¸°ë³¸ í†µê³„
        print(f"\nğŸ“ˆ ì‘ë‹µ ì‹œê°„ í†µê³„")
        print(f"ğŸš¨ ì‘ê¸‰ ìƒí™©:")
        print(f"   í‰ê· : {emergency_result.avg_time:.2f}ì´ˆ")
        print(f"   ìµœì†Œ: {emergency_result.min_time:.2f}ì´ˆ")
        print(f"   ìµœëŒ€: {emergency_result.max_time:.2f}ì´ˆ")
        print(f"   í‘œì¤€í¸ì°¨: {emergency_result.std_dev:.2f}ì´ˆ")
        
        print(f"\nğŸ“ ì¼ë°˜ ì§ˆë¬¸:")
        print(f"   í‰ê· : {normal_result.avg_time:.2f}ì´ˆ")
        print(f"   ìµœì†Œ: {normal_result.min_time:.2f}ì´ˆ")
        print(f"   ìµœëŒ€: {normal_result.max_time:.2f}ì´ˆ")
        print(f"   í‘œì¤€í¸ì°¨: {normal_result.std_dev:.2f}ì´ˆ")
        
        # ì‘ë‹µ ê¸¸ì´ ë¹„êµ
        print(f"\nğŸ“ ì‘ë‹µ ê¸¸ì´ ë¹„êµ")
        print(f"ğŸš¨ ì‘ê¸‰ ìƒí™© í‰ê· : {emergency_result.avg_chars}ì")
        print(f"ğŸ“ ì¼ë°˜ ì§ˆë¬¸ í‰ê· : {normal_result.avg_chars}ì")
        
        # ì„±ëŠ¥ ì°¨ì´ ë¶„ì„
        time_diff = emergency_result.avg_time - normal_result.avg_time
        if time_diff > 0:
            print(f"\nâš ï¸  ì‘ê¸‰ ì²˜ë¦¬ê°€ {time_diff:.2f}ì´ˆ ë” ì†Œìš”")
            print("   â†’ ì•ˆì „ì„±ê³¼ ì •í™•ì„± í–¥ìƒìœ¼ë¡œ ì¸í•œ ì •ìƒì  í˜„ìƒ")
        else:
            improvement = abs(time_diff / normal_result.avg_time) * 100
            print(f"\nâ¬†ï¸  ì‘ê¸‰ ì²˜ë¦¬ê°€ {improvement:.1f}% ë¹¨ë¼ì§")
        
        # ì‘ë‹µ í’ˆì§ˆ ë¶„ì„
        chars_diff = emergency_result.avg_chars - normal_result.avg_chars
        if chars_diff > 0:
            print(f"ğŸ“ˆ ì‘ê¸‰ ìƒí™© ë‹µë³€ì´ {chars_diff}ì ë” ìƒì„¸í•¨")
            print("   â†’ ì•ˆì „ ì •ë³´ì™€ ê²½ê³  ë©”ì‹œì§€ í¬í•¨ìœ¼ë¡œ ì¸í•œ í˜„ìƒ")
        else:
            print(f"ğŸ“‰ ì‘ê¸‰ ìƒí™© ë‹µë³€ì´ {abs(chars_diff)}ì ë” ê°„ê²°í•¨")
        
        return {
            "time_difference": time_diff,
            "chars_difference": chars_diff,
            "emergency_faster": time_diff < 0,
            "emergency_more_detailed": chars_diff > 0
        }
    
    def generate_performance_report(self, emergency_result: BenchmarkResult, 
                                  normal_result: BenchmarkResult, 
                                  comparison: Dict[str, Any]):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\nğŸ“‹ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸")
        print("=" * 60)
        
        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ í™˜ê²½")
        print(f"   ì‘ê¸‰ ìƒí™© ì¿¼ë¦¬: {len(emergency_result.queries)}ê°œ")
        print(f"   ì¼ë°˜ ì§ˆë¬¸ ì¿¼ë¦¬: {len(normal_result.queries)}ê°œ")
        print(f"   ì´ í…ŒìŠ¤íŠ¸ ì‹œê°„: {sum(emergency_result.response_times) + sum(normal_result.response_times):.1f}ì´ˆ")
        
        print(f"\nğŸ¯ í•µì‹¬ ê²°ê³¼")
        if comparison["emergency_faster"]:
            print(f"âœ… ì‘ê¸‰ ì²˜ë¦¬ ì†ë„ ìš°ìˆ˜: {abs(comparison['time_difference']):.2f}ì´ˆ ë¹ ë¦„")
        else:
            print(f"âš ï¸  ì‘ê¸‰ ì²˜ë¦¬ ì‹œê°„ ì¦ê°€: {comparison['time_difference']:.2f}ì´ˆ")
            print("   â†’ ì•ˆì „ì„± ê°•í™”ë¡œ ì¸í•œ í’ˆì§ˆ í–¥ìƒ")
        
        if comparison["emergency_more_detailed"]:
            print(f"ğŸ“ˆ ì‘ê¸‰ ë‹µë³€ ìƒì„¸ë„ í–¥ìƒ: {comparison['chars_difference']}ì ì¶”ê°€")
            print("   â†’ ì•ˆì „ ì§€ì¹¨ ë° ê²½ê³  ë©”ì‹œì§€ í¬í•¨")
        
        print(f"\nğŸ” í’ˆì§ˆ ì§€í‘œ")
        print(f"ğŸš¨ ì‘ê¸‰ ìƒí™© ì¼ê´€ì„±: {emergency_result.std_dev:.2f}ì´ˆ í‘œì¤€í¸ì°¨")
        print(f"ğŸ“ ì¼ë°˜ ì§ˆë¬¸ ì¼ê´€ì„±: {normal_result.std_dev:.2f}ì´ˆ í‘œì¤€í¸ì°¨")
        
        # ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€
        avg_emergency = emergency_result.avg_time
        if avg_emergency < 8:
            grade = "A+ (ìš°ìˆ˜)"
        elif avg_emergency < 12:
            grade = "A (ì–‘í˜¸)"
        elif avg_emergency < 15:
            grade = "B (ë³´í†µ)"
        else:
            grade = "C (ê°œì„  í•„ìš”)"
        
        print(f"\nğŸ† ì‘ê¸‰ ì²˜ë¦¬ ì„±ëŠ¥ ë“±ê¸‰: {grade}")
        
        return {
            "emergency_result": emergency_result,
            "normal_result": normal_result,
            "comparison": comparison,
            "performance_grade": grade
        }
    
    def run_full_benchmark(self):
        """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("ğŸš€ ì „ì²´ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
        print("=" * 60)
        
        # ì‘ê¸‰ ìƒí™© ê°ì§€ ë¶„ì„
        detection_results = self.analyze_emergency_detection()
        
        # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        emergency_result = self.run_benchmark(self.emergency_queries, "ì‘ê¸‰ ìƒí™©", warmup=True)
        normal_result = self.run_benchmark(self.normal_queries, "ì¼ë°˜ ì§ˆë¬¸", warmup=False)
        
        # ì„±ëŠ¥ ë¹„êµ
        comparison = self.compare_performance(emergency_result, normal_result)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = self.generate_performance_report(emergency_result, normal_result, comparison)
        
        print(f"\nğŸ‰ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        return report


def run_performance_tests():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        benchmark = PerformanceBenchmark()
        report = benchmark.run_full_benchmark()
        return report
    except Exception as e:
        print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    run_performance_tests()
