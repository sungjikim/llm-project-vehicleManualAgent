"""
ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ SubGraph
"""

import re
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, START, END

from ...models.states import SearchPipelineState
from ...config.settings import DEFAULT_LLM_MODEL, DEFAULT_LLM_TEMPERATURE, DEFAULT_TOP_K
from ...prompts.templates import VehiclePromptTemplates
from ...tools.search_tools import (
    vector_store, bm25_retriever, multi_query_retriever,
    cross_encoder_retriever, compression_retriever
)


class SearchPipelineSubGraph:
    """ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ SubGraph"""
    
    def __init__(self, search_options: Dict[str, Any], rerank_compression_options: Dict[str, Any]):
        self.llm = ChatOpenAI(
            model=DEFAULT_LLM_MODEL,
            temperature=DEFAULT_LLM_TEMPERATURE
        )
        self.search_options = search_options
        self.rerank_compression_options = rerank_compression_options
        self.analysis_prompt = VehiclePromptTemplates.get_query_analysis_prompt()
    
    def query_analyzer(self, state: SearchPipelineState) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ë¶„ì„ ë…¸ë“œ"""
        query = state["query"]
        is_emergency = state.get("is_emergency", False)
        
        try:
            # ì‘ê¸‰ ìƒí™©ì´ë©´ ì´ë¯¸ ì„¤ì •ëœ ì „ëµ ì‚¬ìš©
            if is_emergency:
                search_strategy = state.get("search_strategy", "troubleshooting")
                search_method = state.get("search_method", "hybrid_keyword")
                compression_method = state.get("compression_method", "rerank_compress_troubleshooting")
                confidence_score = 0.95  # ì‘ê¸‰ ìƒí™©ì€ ë†’ì€ ì‹ ë¢°ë„ë¡œ ì²˜ë¦¬
                
                print(f"ğŸš¨ ì‘ê¸‰ ëª¨ë“œ: {search_strategy} -> {search_method}")
                
                return {
                    "search_strategy": search_strategy,
                    "search_method": search_method,
                    "confidence_score": confidence_score,
                    "compression_method": compression_method
                }
            
            # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
            analysis_chain = self.analysis_prompt | self.llm | StrOutputParser()
            analysis_result = analysis_chain.invoke({"query": query})
            
            # ê²°ê³¼ íŒŒì‹±
            search_strategy = self._extract_field(analysis_result, "ê²€ìƒ‰ ì „ëµ")
            search_method = self._extract_field(analysis_result, "ê²€ìƒ‰ ë°©ë²•")
            confidence_str = self._extract_field(analysis_result, "ì‹ ë¢°ë„")
            
            # ì‹ ë¢°ë„ ì ìˆ˜ ë³€í™˜
            try:
                confidence_score = float(confidence_str)
            except:
                confidence_score = 0.8
            
            # ì¿¼ë¦¬ í™•ì¥ ë° ë‹¤ì¤‘ ì¿¼ë¦¬ ë¡œì§
            original_search_method = search_method
            if any(keyword in query.lower() for keyword in ['êµì²´', 'ë¬¸ì œ', 'ê³ ì¥', 'ì´ìƒ']):
                search_method = "expanded_query"
                print(f"ğŸ”§ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ë°©ë²• ë³€ê²½: {original_search_method} â†’ {search_method}")
            elif len(query) > 20 and '?' in query:
                search_method = "multi_query"
                print(f"ğŸ”§ ë³µì¡í•œ ì§ˆë¬¸ ê°ì§€, ê²€ìƒ‰ ë°©ë²• ë³€ê²½: {original_search_method} â†’ {search_method}")
            
            # ì¬ìˆœìœ„í™”/ì••ì¶• ë°©ë²• ì„ íƒ
            compression_method = self._select_compression_method(search_strategy)
            
            # ê²€ìƒ‰ ì „ëµ ë¡œê·¸ ì¶œë ¥
            print(f"ğŸ“‹ ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼:")
            print(f"   â€¢ ê²€ìƒ‰ ì „ëµ: {search_strategy}")
            print(f"   â€¢ ê²€ìƒ‰ ë°©ë²•: {search_method}")
            print(f"   â€¢ ì‹ ë¢°ë„: {confidence_score}")
            print(f"   â€¢ ì••ì¶• ë°©ë²•: {compression_method}")
            
            return {
                "search_strategy": search_strategy,
                "search_method": search_method,
                "confidence_score": confidence_score,
                "compression_method": compression_method
            }
            
        except Exception as e:
            print(f"ì¿¼ë¦¬ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {
                "search_strategy": "general",
                "search_method": "hybrid_semantic",
                "confidence_score": 0.5,
                "compression_method": "rerank_compress_general"
            }
    
    def search_executor(self, state: SearchPipelineState) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì‹¤í–‰ ë…¸ë“œ"""
        query = state["query"]
        search_method = state.get("search_method", "hybrid_semantic")
        compression_method = state.get("compression_method", "rerank_compress_general")
        
        print(f"ğŸ” ê²€ìƒ‰ ì‹¤í–‰ ì‹œì‘:")
        print(f"   â€¢ ì„ íƒëœ ê²€ìƒ‰ ë°©ë²•: {search_method}")
        print(f"   â€¢ ì••ì¶•/ì¬ìˆœìœ„í™” ë°©ë²•: {compression_method}")
        
        try:
            # 1ì°¨ ê²€ìƒ‰ ìˆ˜í–‰
            if search_method == "expanded_query":
                print("ğŸ” í™•ì¥ ì¿¼ë¦¬ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
                from ...tools.search_tools import expanded_query_search
                search_results = expanded_query_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
            elif search_method == "multi_query":
                print("ğŸ” ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
                from ...tools.search_tools import multi_query_search
                search_results = multi_query_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
            else:
                # ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜í–‰
                print(f"ğŸ” ê¸°ë³¸ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘... (ë°©ë²•: {search_method})")
                retriever = self.search_options.get(search_method)
                if retriever:
                    docs = retriever.invoke(query)
                    search_results = [
                        {
                            "content": doc.page_content,
                            "page": doc.metadata.get("page", 0),
                            "source": doc.metadata.get("source", ""),
                            "score": 1.0
                        }
                        for doc in docs[:DEFAULT_TOP_K]
                    ]
                else:
                    print(f"âŒ ê²€ìƒ‰ ë°©ë²• '{search_method}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    search_results = [{"content": "ê²€ìƒ‰ ë°©ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "page": 0, "score": 0.0}]
            
            print(f"ğŸ“Š 1ì°¨ ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            
            # 2ì°¨ ì¬ìˆœìœ„í™”/ì••ì¶• ì ìš©
            if compression_method and compression_method != "none":
                print(f"ğŸ”„ ì¬ìˆœìœ„í™”/ì••ì¶• ì ìš© ì¤‘... (ë°©ë²•: {compression_method})")
                original_count = len(search_results)
                search_results = self._apply_compression(query, search_results, compression_method)
                print(f"âœ… ì¬ìˆœìœ„í™” ì™„ë£Œ: {original_count}ê°œ â†’ {len(search_results)}ê°œ ë¬¸ì„œ")
            else:
                print("â­ï¸  ì¬ìˆœìœ„í™”/ì••ì¶• ê±´ë„ˆëœ€")
            
            # í˜ì´ì§€ ì°¸ì¡° ì¶”ì¶œ
            page_references = list(set([
                result.get("page", 0) for result in search_results if result.get("page", 0) > 0
            ]))
            
            print(f"ğŸ“„ ìµœì¢… ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ ë¬¸ì„œ, {len(page_references)}ê°œ í˜ì´ì§€ ì°¸ì¡°")
            
            return {
                "search_results": search_results,
                "page_references": page_references
            }
            
        except Exception as e:
            print(f"ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return {
                "search_results": [{"content": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "page": 0, "score": 0.0}],
                "page_references": []
            }
    
    def _extract_field(self, text: str, field_name: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • í•„ë“œ ê°’ ì¶”ì¶œ"""
        pattern = rf"{field_name}:\s*(.+?)(?:\n|$)"
        match = re.search(pattern, text)
        if match:
            return match.group(1).strip()
        return "general" if "ì „ëµ" in field_name else "hybrid_semantic"
    
    def _select_compression_method(self, search_strategy: str) -> str:
        """ê²€ìƒ‰ ì „ëµì— ë”°ë¥¸ ì••ì¶• ë°©ë²• ì„ íƒ"""
        compression_map = {
            "troubleshooting": "rerank_compress_troubleshooting",
            "specific": "rerank_compress_specific",
            "general": "rerank_compress_general"
        }
        return compression_map.get(search_strategy, "rerank_compress_general")
    
    def _apply_compression(self, query: str, search_results: List[Dict], compression_method: str) -> List[Dict]:
        """ì••ì¶•/ì¬ìˆœìœ„í™” ì ìš©"""
        try:
            retriever = self.rerank_compression_options.get(compression_method)
            if retriever:
                # ì••ì¶• ê²€ìƒ‰ ìˆ˜í–‰
                if compression_method.startswith("rerank_compress"):
                    from ...tools.search_tools import cross_encoder_rerank_search
                    return cross_encoder_rerank_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
                else:
                    from ...tools.search_tools import contextual_compression_search
                    return contextual_compression_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
            
        except Exception as e:
            print(f"ì••ì¶• ì ìš© ì˜¤ë¥˜: {str(e)}")
        
        return search_results
    
    def create_graph(self) -> StateGraph:
        """ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ SubGraph ìƒì„±"""
        workflow = StateGraph(SearchPipelineState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("query_analyzer", self.query_analyzer)
        workflow.add_node("search_executor", self.search_executor)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("query_analyzer")
        workflow.add_edge("query_analyzer", "search_executor")
        workflow.add_edge("search_executor", END)
        
        return workflow.compile()
    
    def invoke(self, query: str, is_emergency: bool = False, emergency_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """SubGraph ì‹¤í–‰"""
        graph = self.create_graph()
        
        initial_state = {
            "query": query,
            "search_strategy": "",
            "search_method": "",
            "compression_method": "",
            "confidence_score": 0.0,
            "search_results": [],
            "page_references": []
        }
        
        # ì‘ê¸‰ ìƒí™© ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if is_emergency and emergency_data:
            initial_state.update({
                "is_emergency": True,
                "search_strategy": emergency_data.get("search_strategy", "troubleshooting"),
                "search_method": emergency_data.get("search_method", "hybrid_keyword"),
                "compression_method": emergency_data.get("compression_method", "rerank_compress_troubleshooting")
            })
        
        return graph.invoke(initial_state)
