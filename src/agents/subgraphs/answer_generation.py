"""
ë‹µë³€ ìƒì„± SubGraph
"""

from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, START, END

from ...models.states import AnswerGenerationState
from ...config.settings import DEFAULT_LLM_MODEL, DEFAULT_LLM_TEMPERATURE
from ...prompts.templates import VehiclePromptTemplates
from ...utils.answer_evaluator import AnswerEvaluator
from ...utils.emergency_detector import EmergencyDetector


class AnswerGenerationSubGraph:
    """ë‹µë³€ ìƒì„± SubGraph"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=DEFAULT_LLM_MODEL,
            temperature=DEFAULT_LLM_TEMPERATURE
        )
        self.answer_evaluator = AnswerEvaluator()
        self.emergency_detector = EmergencyDetector()
        self.answer_prompt = VehiclePromptTemplates.get_answer_generation_prompt()
    
    def answer_generator(self, state: AnswerGenerationState) -> Dict[str, Any]:
        """ë‹µë³€ ìƒì„± ë…¸ë“œ"""
        query = state["query"]
        search_results = state.get("search_results", [])
        page_references = state.get("page_references", [])
        is_emergency = state.get("is_emergency", False)
        emergency_level = state.get("emergency_level", "NORMAL")
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (í˜ì´ì§€ ì •ë³´ ê°•í™”)
            context_parts = []
            valid_pages = []
            
            for i, result in enumerate(search_results[:5], 1):
                content = result.get("content", "")
                page = result.get("page", 0)
                score = result.get("score", 0.0)
                
                if page > 0:
                    valid_pages.append(page)
                    context_parts.append(f"[ê²€ìƒ‰ê²°ê³¼ {i}] (í˜ì´ì§€ {page}, ê´€ë ¨ë„: {score:.2f})\n{content}")
                else:
                    context_parts.append(f"[ê²€ìƒ‰ê²°ê³¼ {i}] (ê´€ë ¨ë„: {score:.2f})\n{content}")
            
            context = "\n\n".join(context_parts)
            
            # ì‘ê¸‰ ìƒí™© í”„ë¡¬í”„íŠ¸ ê°•í™”
            emergency_enhancement = ""
            if is_emergency:
                emergency_enhancement = self.emergency_detector.get_emergency_prompt_enhancement(emergency_level)
                context = emergency_enhancement + "\n\n" + context
                print(f"ğŸš¨ ì‘ê¸‰ ë‹µë³€ ìƒì„± ëª¨ë“œ: {emergency_level}")
            
            # í˜ì´ì§€ ì°¸ì¡° ì •ë³´ ì¶”ê°€
            page_info = ""
            if valid_pages:
                unique_pages = sorted(list(set(valid_pages)))
                if len(unique_pages) == 1:
                    page_info = f"\n\nğŸ“š ì°¸ê³  í˜ì´ì§€: {unique_pages[0]}"
                elif len(unique_pages) <= 3:
                    page_info = f"\n\nğŸ“š ì°¸ê³  í˜ì´ì§€: {', '.join(map(str, unique_pages))}"
                else:
                    page_info = f"\n\nğŸ“š ì£¼ìš” ì°¸ê³  í˜ì´ì§€: {', '.join(map(str, unique_pages[:3]))} ì™¸"
            
            # Few-shot í”„ë¡¬í”„íŠ¸ë¡œ ë‹µë³€ ìƒì„±
            answer_chain = self.answer_prompt | self.llm | StrOutputParser()
            final_answer = answer_chain.invoke({
                "query": query,
                "context": context
            })
            
            # í˜ì´ì§€ ì •ë³´ê°€ ë‹µë³€ì— ì—†ìœ¼ë©´ ì¶”ê°€
            if page_info and "ğŸ“š" not in final_answer:
                final_answer += page_info
            
            # ì‘ê¸‰ ìƒí™© ë“±ê¸‰ í‘œì‹œë¥¼ ë‹µë³€ ì²« ì¤„ì— ì¶”ê°€
            emergency_header = ""
            if is_emergency:
                # ì‘ê¸‰ ìƒí™© í—¤ë” ìƒì„±
                emergency_icons = {
                    "CRITICAL": "ğŸ”¥",
                    "HIGH": "ğŸš¨", 
                    "MEDIUM": "âš ï¸",
                    "LOW": "ğŸ”"
                }
                icon = emergency_icons.get(emergency_level, "ğŸš¨")
                emergency_header = f"{icon} **{emergency_level} ì‘ê¸‰ ìƒí™©**\n\n"
                
                # ì‘ê¸‰ ìƒí™©ì—ì„œëŠ” ì‹ ë¢°ë„ í‰ê°€ ê°„ì†Œí™” (ì†ë„ ìš°ì„ )
                confidence_percentage = 85.0  # ì‘ê¸‰ ìƒí™© ê¸°ë³¸ ì‹ ë¢°ë„
                reliability_grade = "ë†’ìŒ (A)"
                
                # ì‘ê¸‰ ìƒí™© ê²½ê³  ì¶”ê°€
                emergency_warning = f"\n\nğŸš¨ **ì‘ê¸‰ ìƒí™© ({emergency_level})**"
                if emergency_level == "CRITICAL":
                    emergency_warning += "\nâš ï¸ ìƒëª… ìœ„í—˜ ìƒí™©ì…ë‹ˆë‹¤. ì¦‰ì‹œ ì¡°ì¹˜í•˜ê³  119ì— ì‹ ê³ í•˜ì„¸ìš”."
                elif emergency_level == "HIGH":
                    emergency_warning += "\nâš ï¸ ì¦‰ì‹œ ì•ˆì „ ì¡°ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì „ë¬¸ê°€ì—ê²Œ ì—°ë½í•˜ì„¸ìš”."
                else:
                    emergency_warning += "\nâš ï¸ ì‹ ì†í•œ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤."
                
                final_answer = emergency_header + final_answer + emergency_warning
            else:
                # ì¼ë°˜ ì§ˆë¬¸ í—¤ë” ìƒì„±
                emergency_header = "ğŸ“ **ì¼ë°˜ ì§ˆë¬¸**\n\n"
                
                # ì¼ë°˜ ìƒí™© ì‹ ë¢°ë„ í‰ê°€
                evaluation = self.answer_evaluator.evaluate_answer(query, final_answer, search_results)
                confidence_percentage = evaluation['percentage']
                reliability_grade = evaluation['reliability_grade']
                
                final_answer = emergency_header + final_answer
            
            # ì‹ ë¢°ë„ ì •ë³´ë¥¼ ë‹µë³€ì— ì¶”ê°€
            confidence_info = f"\n\nğŸ” **ë‹µë³€ ì‹ ë¢°ë„**: {confidence_percentage}% ({reliability_grade})"
            
            # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì¶”ê°€ ì•ˆë‚´ (ì‘ê¸‰ ìƒí™©ì´ ì•„ë‹ ë•Œë§Œ)
            if not is_emergency:
                if confidence_percentage >= 80:
                    confidence_info += "\nâœ… ë†’ì€ ì‹ ë¢°ë„ì˜ ë‹µë³€ì…ë‹ˆë‹¤."
                elif confidence_percentage >= 60:
                    confidence_info += "\nâš ï¸ ì¶”ê°€ í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                else:
                    confidence_info += "\nâŒ ì „ë¬¸ê°€ ìƒë‹´ì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤."
            
            final_answer_with_confidence = final_answer + confidence_info
            
            # ì‘ê¸‰ ìƒí™©ì—ì„œ evaluation ë³€ìˆ˜ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²˜ë¦¬
            if is_emergency and 'evaluation' not in locals():
                evaluation = {
                    "total_score": confidence_percentage / 100,
                    "percentage": confidence_percentage,
                    "reliability_grade": reliability_grade,
                    "emergency_mode": True,
                    "emergency_level": emergency_level
                }
            
            return {
                "final_answer": final_answer_with_confidence,
                "confidence_score": confidence_percentage / 100,
                "evaluation_details": evaluation if 'evaluation' in locals() else None
            }
            
        except Exception as e:
            print(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {"final_answer": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}
    
    def create_graph(self) -> StateGraph:
        """ë‹µë³€ ìƒì„± SubGraph ìƒì„±"""
        workflow = StateGraph(AnswerGenerationState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("answer_generator", self.answer_generator)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("answer_generator")
        workflow.add_edge("answer_generator", END)
        
        return workflow.compile()
    
    def invoke(self, query: str, search_results: List[Dict[str, Any]], 
               page_references: List[int], is_emergency: bool = False, 
               emergency_level: str = "NORMAL") -> Dict[str, Any]:
        """SubGraph ì‹¤í–‰"""
        graph = self.create_graph()
        
        initial_state = {
            "query": query,
            "search_results": search_results,
            "page_references": page_references,
            "is_emergency": is_emergency,
            "emergency_level": emergency_level,
            "final_answer": "",
            "confidence_score": 0.0,
            "evaluation_details": None
        }
        
        return graph.invoke(initial_state)
