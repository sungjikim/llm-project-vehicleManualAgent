"""
ì£¼í–‰ ìƒí™© ì²˜ë¦¬ SubGraph
"""

from typing import Dict, Any
from langgraph.graph import StateGraph, START, END

from ...models.subgraph_states import DrivingContextState
from ...utils.driving_context_detector import DrivingContextDetector


class DrivingContextSubGraph:
    """ì£¼í–‰ ìƒí™© ì²˜ë¦¬ SubGraph"""
    
    def __init__(self):
        self.driving_detector = DrivingContextDetector()
    
    def driving_context_processor(self, state: DrivingContextState) -> Dict[str, Any]:
        """ì£¼í–‰ ì¤‘ ìƒí™© ê°ì§€ ë° ë‹µë³€ ì••ì¶• ë…¸ë“œ"""
        query = state["query"]
        original_answer = state.get("original_answer", "")
        
        # Emergency ì •ë³´ ì°¸ì¡° (ì •ë³´ ê³µìœ  ìµœì í™”)
        is_emergency = state.get("is_emergency", False)
        emergency_level = state.get("emergency_level", "NORMAL")
        
        try:
            print("ðŸš— ì£¼í–‰ ìƒí™© ë¶„ì„ ì¤‘...")
            
            # 1. ì£¼í–‰ ì¤‘ ìƒí™© ê°ì§€ (Emergency ì •ë³´ í™œìš©)
            if is_emergency and emergency_level in ["CRITICAL", "HIGH"]:
                # ì‘ê¸‰ ìƒí™©ì´ë©´ ì£¼í–‰ ì¤‘ìœ¼ë¡œ ê°€ì •í•˜ê³  ê°„ì†Œí™”ëœ ë¶„ì„
                print("âš¡ ì‘ê¸‰ ìƒí™© ê°ì§€ë¨ - ì£¼í–‰ ì¤‘ìœ¼ë¡œ ê°€ì •")
                is_driving = True
                confidence = 0.95
                urgency_level = "immediate" if emergency_level == "CRITICAL" else "urgent"
                driving_analysis = {
                    "is_driving": True,
                    "confidence": confidence,
                    "urgency_level": urgency_level,
                    "compression_needed": True,
                    "driving_indicators": [f"ì‘ê¸‰ìƒí™©({emergency_level})"]
                }
            else:
                # ì¼ë°˜ ìƒí™©ì—ì„œë§Œ ìƒì„¸ ì£¼í–‰ ë¶„ì„ ìˆ˜í–‰
                driving_analysis = self.driving_detector.detect_driving_context(query)
                is_driving = driving_analysis["is_driving"]
                confidence = driving_analysis["confidence"]
                urgency_level = driving_analysis["urgency_level"]
            
            print(f"ðŸš— ì£¼í–‰ ìƒí™© ë¶„ì„ ê²°ê³¼:")
            print(f"   â€¢ ì£¼í–‰ ì¤‘ ì—¬ë¶€: {is_driving} (ì‹ ë¢°ë„: {confidence:.2f})")
            print(f"   â€¢ ê¸´ê¸‰ë„: {urgency_level}")
            
            if driving_analysis["driving_indicators"]:
                indicators = ", ".join(driving_analysis["driving_indicators"])
                print(f"   â€¢ ê°ì§€ëœ ì§€í‘œ: {indicators}")
            
            # 2. ì£¼í–‰ ì¤‘ì´ë©´ ë‹µë³€ ì••ì¶•
            if is_driving and driving_analysis["compression_needed"]:
                print("ðŸ“± ì£¼í–‰ ì¤‘ ëª¨ë“œ - ë‹µë³€ ì••ì¶• ì¤‘...")
                
                compression_result = self.driving_detector.compress_answer(
                    original_answer, query, urgency_level
                )
                
                compressed_answer = compression_result["compressed_answer"]
                compression_ratio = compression_result["compression_ratio"]
                
                print(f"âœ… ë‹µë³€ ì••ì¶• ì™„ë£Œ (ì••ì¶•ë¥ : {compression_ratio:.1%})")
                
                # ì£¼í–‰ ì¤‘ ì•ˆì „ ë©”ì‹œì§€ ì¶”ê°€
                if urgency_level == "immediate":
                    safety_message = "\n\nðŸ›‘ **ì¦‰ì‹œ ì•ˆì „í•œ ê³³ì— ì •ì°¨í•˜ì„¸ìš”**"
                elif urgency_level == "urgent":
                    safety_message = "\n\nâš ï¸ **ê°€ëŠ¥í•œ ë¹¨ë¦¬ ì•ˆì „í•œ ê³³ì—ì„œ í™•ì¸í•˜ì„¸ìš”**"
                else:
                    safety_message = "\n\nðŸ“‹ **ì£¼í–‰ í›„ ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”**"
                
                final_compressed = compressed_answer + safety_message
                
                return {
                    "is_driving": True,
                    "driving_confidence": confidence,
                    "driving_indicators": driving_analysis["driving_indicators"],
                    "driving_urgency": urgency_level,
                    "compression_needed": True,
                    "compressed_answer": final_compressed,
                    "final_answer": final_compressed  # ìµœì¢… ë‹µë³€ì„ ì••ì¶•ëœ ë²„ì „ìœ¼ë¡œ ëŒ€ì²´
                }
            
            else:
                # ì£¼í–‰ ì¤‘ì´ ì•„ë‹ˆê±°ë‚˜ ì••ì¶•ì´ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš°
                print("ðŸ  ì¼ë°˜ ëª¨ë“œ - ì›ë³¸ ë‹µë³€ ìœ ì§€")
                
                return {
                    "is_driving": False,
                    "driving_confidence": confidence,
                    "driving_indicators": driving_analysis.get("driving_indicators", []),
                    "driving_urgency": "normal",
                    "compression_needed": False,
                    "compressed_answer": "",
                    "final_answer": original_answer  # ì›ë³¸ ë‹µë³€ ìœ ì§€
                }
                
        except Exception as e:
            print(f"ì£¼í–‰ ìƒí™© ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë‹µë³€ ìœ ì§€
            return {
                "is_driving": False,
                "driving_confidence": 0.0,
                "driving_indicators": [],
                "driving_urgency": "normal",
                "compression_needed": False,
                "compressed_answer": "",
                "final_answer": original_answer
            }
    
    def create_graph(self) -> StateGraph:
        """ì£¼í–‰ ìƒí™© ì²˜ë¦¬ SubGraph ìƒì„±"""
        workflow = StateGraph(DrivingContextState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("driving_context_processor", self.driving_context_processor)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("driving_context_processor")
        workflow.add_edge("driving_context_processor", END)
        
        return workflow.compile()
    
    def invoke(self, query: str, original_answer: str, is_emergency: bool = False, 
               emergency_level: str = "NORMAL") -> Dict[str, Any]:
        """SubGraph ì‹¤í–‰"""
        graph = self.create_graph()
        
        initial_state = {
            "query": query,
            "original_answer": original_answer,
            "is_emergency": is_emergency,
            "emergency_level": emergency_level,
            "is_driving": False,
            "driving_confidence": 0.0,
            "driving_indicators": [],
            "driving_urgency": "normal",
            "compression_needed": False,
            "compressed_answer": "",
            "final_answer": ""
        }
        
        return graph.invoke(initial_state)
