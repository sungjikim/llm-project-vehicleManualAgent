"""
ì°¨ëŸ‰ ë§¤ë‰´ì–¼ RAG ì—ì´ì „íŠ¸
"""

import re
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.retrievers import EnsembleRetriever
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END

from ..models.state import AgentState
from ..config.settings import (
    DEFAULT_LLM_MODEL, DEFAULT_LLM_TEMPERATURE, DEFAULT_TOP_K, WEIGHT_CONFIGS
)
from ..retrievers.vector_retriever import VectorStoreManager
from ..retrievers.hybrid_retriever import HybridRetrieverManager
from ..retrievers.compression_retriever import CompressionRetrieverManager
from ..prompts.templates import VehiclePromptTemplates
from ..utils.document_loader import DocumentLoader
from ..tools.search_tools import (
    vector_store, bm25_retriever, hybrid_retriever, multi_query_retriever,
    cross_encoder_retriever, compression_retriever
)


class VehicleManualAgent:
    """ì°¨ëŸ‰ ë§¤ë‰´ì–¼ RAG ì—ì´ì „íŠ¸"""
    
    def __init__(self, pdf_path: str):
        # LLM ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model=DEFAULT_LLM_MODEL,
            temperature=DEFAULT_LLM_TEMPERATURE
        )
        self.embeddings = OpenAIEmbeddings()
        
        # ë¬¸ì„œ ë¡œë” ì´ˆê¸°í™”
        self.document_loader = DocumentLoader()
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ˆê¸°í™”
        self.analysis_prompt = VehiclePromptTemplates.get_query_analysis_prompt()
        self.answer_prompt = VehiclePromptTemplates.get_answer_generation_prompt()
        
        # ê²€ìƒ‰ê¸° ê´€ë¦¬ìë“¤ ì´ˆê¸°í™”
        self.vector_manager = VectorStoreManager(pdf_path)
        self.hybrid_manager = None
        self.compression_manager = None
        
        # ê²€ìƒ‰ ì˜µì…˜ ì„¤ì •
        self.search_options = {}
        self.rerank_compression_options = {}
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_system()
    
    def _initialize_system(self):
        """ì‹œìŠ¤í…œ ì „ì²´ ì´ˆê¸°í™”"""
        print("ğŸš€ ì°¨ëŸ‰ ë§¤ë‰´ì–¼ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # 1. ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
        vector_store_instance = self.vector_manager.initialize_vector_store()
        if vector_store_instance is None:
            raise Exception("ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ì „ì—­ ë³€ìˆ˜ ì„¤ì •
        global vector_store
        vector_store = vector_store_instance
        
        # 2. ë¬¸ì„œ ë¡œë“œ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°ìš©)
        documents = self.document_loader.load_and_split_pdf(self.vector_manager.pdf_path)
        if not documents:
            raise Exception("ë¬¸ì„œ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self.hybrid_manager = HybridRetrieverManager(vector_store_instance, self.llm)
        self.hybrid_manager.initialize_bm25_retriever(documents)
        self.hybrid_manager.initialize_multi_query_retriever()
        
        # ì „ì—­ ë³€ìˆ˜ ì„¤ì •
        global bm25_retriever, multi_query_retriever
        bm25_retriever = self.hybrid_manager.get_bm25_retriever()
        multi_query_retriever = self.hybrid_manager.get_multi_query_retriever()
        
        # 4. ì••ì¶•/ì¬ìˆœìœ„í™” ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self.compression_manager = CompressionRetrieverManager(
            vector_store_instance, self.embeddings, self.llm
        )
        self.compression_manager.initialize_cross_encoder_retriever()
        self.compression_manager.initialize_contextual_compression()
        
        # ì „ì—­ ë³€ìˆ˜ ì„¤ì •
        global cross_encoder_retriever, compression_retriever
        cross_encoder_retriever = self.compression_manager.get_cross_encoder_retriever()
        compression_retriever = self.compression_manager.get_compression_retriever()
        
        # 5. ê²€ìƒ‰ ì˜µì…˜ ì„¤ì •
        self._setup_search_options()
        
        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def _setup_search_options(self):
        """ê²€ìƒ‰ ì˜µì…˜ ì„¤ì •"""
        semantic_retriever = vector_store.as_retriever(search_kwargs={"k": DEFAULT_TOP_K})
        
        self.search_options = {
            "vector_only": semantic_retriever,
            "bm25_only": bm25_retriever,
            "hybrid_semantic": EnsembleRetriever(
                retrievers=[semantic_retriever, bm25_retriever],
                weights=[WEIGHT_CONFIGS["hybrid_semantic"], 1 - WEIGHT_CONFIGS["hybrid_semantic"]]
            ),
            "hybrid_balanced": EnsembleRetriever(
                retrievers=[semantic_retriever, bm25_retriever],
                weights=[WEIGHT_CONFIGS["hybrid_balanced"], 1 - WEIGHT_CONFIGS["hybrid_balanced"]]
            ),
            "hybrid_keyword": EnsembleRetriever(
                retrievers=[semantic_retriever, bm25_retriever],
                weights=[WEIGHT_CONFIGS["hybrid_keyword"], 1 - WEIGHT_CONFIGS["hybrid_keyword"]]
            ),
            "multi_query": multi_query_retriever,
            "expanded_query": self.search_options.get("hybrid_semantic")  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
        }
        
        # ì¬ìˆœìœ„í™” ë° ì••ì¶• ì˜µì…˜
        self.rerank_compression_options = {
            "rerank_only": cross_encoder_retriever,
            "compress_only": compression_retriever,
            "rerank_compress_general": cross_encoder_retriever,
            "rerank_compress_specific": compression_retriever,
            "rerank_compress_troubleshooting": cross_encoder_retriever
        }
    
    def query_analyzer(self, state: AgentState) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ë¶„ì„ ë…¸ë“œ"""
        query = state["query"]
        
        try:
            # Few-shot í”„ë¡¬í”„íŠ¸ë¡œ ì¿¼ë¦¬ ë¶„ì„
            analysis_chain = self.analysis_prompt | self.llm | StrOutputParser()
            analysis_result = analysis_chain.invoke({"query": query})
            
            # ê²°ê³¼ íŒŒì‹±
            search_strategy = self._extract_field(analysis_result, "ê²€ìƒ‰ ì „ëµ")
            search_method = self._extract_field(analysis_result, "ê²€ìƒ‰ ë°©ë²•")
            confidence_str = self._extract_field(analysis_result, "ì‹ ë¢°ë„")
            
            # ì‹ ë¢°ë„ ì ìˆ˜ ë³€í™˜
            try:
                confidence_score = float(confidence_str)
            except:
                confidence_score = 0.8
            
            # ì¿¼ë¦¬ í™•ì¥ ë° ë‹¤ì¤‘ ì¿¼ë¦¬ ë¡œì§
            if any(keyword in query.lower() for keyword in ['êµì²´', 'ë¬¸ì œ', 'ê³ ì¥', 'ì´ìƒ']):
                search_method = "expanded_query"
            elif len(query) > 20 and '?' in query:
                search_method = "multi_query"
            
            # ì¬ìˆœìœ„í™”/ì••ì¶• ë°©ë²• ì„ íƒ
            compression_method = self._select_compression_method(search_strategy)
            
            return {
                "search_strategy": search_strategy,
                "search_method": search_method,
                "confidence_score": confidence_score,
                "compression_method": compression_method
            }
            
        except Exception as e:
            print(f"ì¿¼ë¦¬ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {
                "search_strategy": "general",
                "search_method": "hybrid_semantic",
                "confidence_score": 0.5,
                "compression_method": "rerank_compress_general"
            }
    
    def search_executor(self, state: AgentState) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì‹¤í–‰ ë…¸ë“œ"""
        query = state["query"]
        search_method = state.get("search_method", "hybrid_semantic")
        compression_method = state.get("compression_method", "rerank_compress_general")
        
        try:
            # 1ì°¨ ê²€ìƒ‰ ìˆ˜í–‰
            if search_method == "expanded_query":
                from ..tools.search_tools import expanded_query_search
                search_results = expanded_query_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
            elif search_method == "multi_query":
                from ..tools.search_tools import multi_query_search
                search_results = multi_query_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
            else:
                # ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜í–‰
                retriever = self.search_options.get(search_method)
                if retriever:
                    docs = retriever.invoke(query)
                    search_results = [
                        {
                            "content": doc.page_content,
                            "page": doc.metadata.get("page", 0),
                            "source": doc.metadata.get("source", ""),
                            "score": 1.0
                        }
                        for doc in docs[:DEFAULT_TOP_K]
                    ]
                else:
                    search_results = [{"content": "ê²€ìƒ‰ ë°©ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "page": 0, "score": 0.0}]
            
            # 2ì°¨ ì¬ìˆœìœ„í™”/ì••ì¶• ì ìš©
            if compression_method and compression_method != "none":
                search_results = self._apply_compression(query, search_results, compression_method)
            
            # í˜ì´ì§€ ì°¸ì¡° ì¶”ì¶œ
            page_references = list(set([
                result.get("page", 0) for result in search_results if result.get("page", 0) > 0
            ]))
            
            return {
                "search_results": search_results,
                "page_references": page_references
            }
            
        except Exception as e:
            print(f"ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return {
                "search_results": [{"content": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "page": 0, "score": 0.0}],
                "page_references": []
            }
    
    def answer_generator(self, state: AgentState) -> Dict[str, Any]:
        """ë‹µë³€ ìƒì„± ë…¸ë“œ"""
        query = state["query"]
        search_results = state.get("search_results", [])
        page_references = state.get("page_references", [])
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (í˜ì´ì§€ ì •ë³´ ê°•í™”)
            context_parts = []
            valid_pages = []
            
            for i, result in enumerate(search_results[:5], 1):
                content = result.get("content", "")
                page = result.get("page", 0)
                score = result.get("score", 0.0)
                
                if page > 0:
                    valid_pages.append(page)
                    context_parts.append(f"[ê²€ìƒ‰ê²°ê³¼ {i}] (í˜ì´ì§€ {page}, ê´€ë ¨ë„: {score:.2f})\n{content}")
                else:
                    context_parts.append(f"[ê²€ìƒ‰ê²°ê³¼ {i}] (ê´€ë ¨ë„: {score:.2f})\n{content}")
            
            context = "\n\n".join(context_parts)
            
            # í˜ì´ì§€ ì°¸ì¡° ì •ë³´ ì¶”ê°€
            page_info = ""
            if valid_pages:
                unique_pages = sorted(list(set(valid_pages)))
                if len(unique_pages) == 1:
                    page_info = f"\n\nğŸ“š ì°¸ê³  í˜ì´ì§€: {unique_pages[0]}"
                elif len(unique_pages) <= 3:
                    page_info = f"\n\nğŸ“š ì°¸ê³  í˜ì´ì§€: {', '.join(map(str, unique_pages))}"
                else:
                    page_info = f"\n\nğŸ“š ì£¼ìš” ì°¸ê³  í˜ì´ì§€: {', '.join(map(str, unique_pages[:3]))} ì™¸"
            
            # Few-shot í”„ë¡¬í”„íŠ¸ë¡œ ë‹µë³€ ìƒì„±
            answer_chain = self.answer_prompt | self.llm | StrOutputParser()
            final_answer = answer_chain.invoke({
                "query": query,
                "context": context
            })
            
            # í˜ì´ì§€ ì •ë³´ê°€ ë‹µë³€ì— ì—†ìœ¼ë©´ ì¶”ê°€
            if page_info and "ğŸ“š" not in final_answer:
                final_answer += page_info
            
            return {"final_answer": final_answer}
            
        except Exception as e:
            print(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {"final_answer": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}
    
    def _extract_field(self, text: str, field_name: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • í•„ë“œ ê°’ ì¶”ì¶œ"""
        pattern = rf"{field_name}:\s*(.+?)(?:\n|$)"
        match = re.search(pattern, text)
        if match:
            return match.group(1).strip()
        return "general" if "ì „ëµ" in field_name else "hybrid_semantic"
    
    def _select_compression_method(self, search_strategy: str) -> str:
        """ê²€ìƒ‰ ì „ëµì— ë”°ë¥¸ ì••ì¶• ë°©ë²• ì„ íƒ"""
        compression_map = {
            "troubleshooting": "rerank_compress_troubleshooting",
            "specific": "rerank_compress_specific",
            "general": "rerank_compress_general"
        }
        return compression_map.get(search_strategy, "rerank_compress_general")
    
    def _apply_compression(self, query: str, search_results: List[Dict], compression_method: str) -> List[Dict]:
        """ì••ì¶•/ì¬ìˆœìœ„í™” ì ìš©"""
        try:
            retriever = self.rerank_compression_options.get(compression_method)
            if retriever:
                # ì••ì¶• ê²€ìƒ‰ ìˆ˜í–‰
                if compression_method.startswith("rerank_compress"):
                    from ..tools.search_tools import cross_encoder_rerank_search
                    return cross_encoder_rerank_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
                else:
                    from ..tools.search_tools import contextual_compression_search
                    return contextual_compression_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
            
        except Exception as e:
            print(f"ì••ì¶• ì ìš© ì˜¤ë¥˜: {str(e)}")
        
        return search_results
    
    def create_graph(self) -> StateGraph:
        """LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(AgentState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("query_analyzer", self.query_analyzer)
        workflow.add_node("search_executor", self.search_executor)
        workflow.add_node("answer_generator", self.answer_generator)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("query_analyzer")
        workflow.add_edge("query_analyzer", "search_executor")
        workflow.add_edge("search_executor", "answer_generator")
        workflow.add_edge("answer_generator", END)
        
        return workflow.compile()
    
    def query(self, user_query: str) -> str:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬"""
        try:
            graph = self.create_graph()
            
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = {
                "messages": [],
                "query": user_query,
                "search_results": [],
                "context": "",
                "final_answer": "",
                "search_strategy": "",
                "search_method": "",
                "confidence_score": 0.0,
                "page_references": [],
                "need_clarification": False
            }
            
            # ê·¸ë˜í”„ ì‹¤í–‰
            result = graph.invoke(initial_state)
            
            return result.get("final_answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            return f"ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
