"""
ì°¨ëŸ‰ ë§¤ë‰´ì–¼ RAG ì—ì´ì „íŠ¸
"""

import re
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.retrievers import EnsembleRetriever
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END

from ..models.state import AgentState
from ..config.settings import (
    DEFAULT_LLM_MODEL, DEFAULT_LLM_TEMPERATURE, DEFAULT_TOP_K, WEIGHT_CONFIGS
)
from ..retrievers.vector_retriever import VectorStoreManager
from ..retrievers.hybrid_retriever import HybridRetrieverManager
from ..retrievers.compression_retriever import CompressionRetrieverManager
from ..prompts.templates import VehiclePromptTemplates
from ..utils.document_loader import DocumentLoader
from ..utils.answer_evaluator import AnswerEvaluator
from ..utils.emergency_detector import EmergencyDetector
from ..utils.driving_context_detector import DrivingContextDetector
from ..tools.search_tools import (
    vector_store, bm25_retriever, hybrid_retriever, multi_query_retriever,
    cross_encoder_retriever, compression_retriever
)


class VehicleManualAgent:
    """ì°¨ëŸ‰ ë§¤ë‰´ì–¼ RAG ì—ì´ì „íŠ¸"""
    
    def __init__(self, pdf_path: str):
        # LLM ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model=DEFAULT_LLM_MODEL,
            temperature=DEFAULT_LLM_TEMPERATURE
        )
        self.embeddings = OpenAIEmbeddings()
        
        # ë¬¸ì„œ ë¡œë” ì´ˆê¸°í™”
        self.document_loader = DocumentLoader()
        
        # ë‹µë³€ í‰ê°€ê¸° ì´ˆê¸°í™”
        self.answer_evaluator = AnswerEvaluator()
        
        # ì‘ê¸‰ ìƒí™© ê°ì§€ê¸° ì´ˆê¸°í™”
        self.emergency_detector = EmergencyDetector()
        
        # ì£¼í–‰ ìƒí™© ê°ì§€ê¸° ì´ˆê¸°í™”
        self.driving_detector = DrivingContextDetector()
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ˆê¸°í™”
        self.analysis_prompt = VehiclePromptTemplates.get_query_analysis_prompt()
        self.answer_prompt = VehiclePromptTemplates.get_answer_generation_prompt()
        
        # ê²€ìƒ‰ê¸° ê´€ë¦¬ìë“¤ ì´ˆê¸°í™”
        self.vector_manager = VectorStoreManager(pdf_path)
        self.hybrid_manager = None
        self.compression_manager = None
        
        # ê²€ìƒ‰ ì˜µì…˜ ì„¤ì •
        self.search_options = {}
        self.rerank_compression_options = {}
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_system()
    
    def _initialize_system(self):
        """ì‹œìŠ¤í…œ ì „ì²´ ì´ˆê¸°í™”"""
        print("ğŸš€ ì°¨ëŸ‰ ë§¤ë‰´ì–¼ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # 1. ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
        vector_store_instance = self.vector_manager.initialize_vector_store()
        if vector_store_instance is None:
            raise Exception("ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ì „ì—­ ë³€ìˆ˜ ì„¤ì •
        global vector_store
        vector_store = vector_store_instance
        
        # 2. ë¬¸ì„œ ë¡œë“œ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°ìš©)
        documents = self.document_loader.load_and_split_pdf(self.vector_manager.pdf_path)
        if not documents:
            raise Exception("ë¬¸ì„œ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self.hybrid_manager = HybridRetrieverManager(vector_store_instance, self.llm)
        self.hybrid_manager.initialize_bm25_retriever(documents)
        self.hybrid_manager.initialize_multi_query_retriever()
        
        # ì „ì—­ ë³€ìˆ˜ ì„¤ì •
        global bm25_retriever, multi_query_retriever
        bm25_retriever = self.hybrid_manager.get_bm25_retriever()
        multi_query_retriever = self.hybrid_manager.get_multi_query_retriever()
        
        # 4. ì••ì¶•/ì¬ìˆœìœ„í™” ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        self.compression_manager = CompressionRetrieverManager(
            vector_store_instance, self.embeddings, self.llm
        )
        self.compression_manager.initialize_cross_encoder_retriever()
        self.compression_manager.initialize_contextual_compression()
        
        # search_tools ëª¨ë“ˆì˜ ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
        import src.tools.search_tools as search_tools
        search_tools.vector_store = vector_store
        search_tools.bm25_retriever = bm25_retriever
        search_tools.hybrid_retriever = None  # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°ëŠ” EnsembleRetrieverë¡œ ë™ì  ìƒì„±ë¨
        search_tools.multi_query_retriever = multi_query_retriever
        search_tools.cross_encoder_retriever = self.compression_manager.get_cross_encoder_retriever()
        search_tools.compression_retriever = self.compression_manager.get_compression_retriever()
        
        # 5. ê²€ìƒ‰ ì˜µì…˜ ì„¤ì •
        self._setup_search_options()
        
        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def _setup_search_options(self):
        """ê²€ìƒ‰ ì˜µì…˜ ì„¤ì •"""
        semantic_retriever = vector_store.as_retriever(search_kwargs={"k": DEFAULT_TOP_K})
        
        self.search_options = {
            "vector_only": semantic_retriever,
            "bm25_only": bm25_retriever,
            "hybrid_semantic": EnsembleRetriever(
                retrievers=[semantic_retriever, bm25_retriever],
                weights=[WEIGHT_CONFIGS["hybrid_semantic"], 1 - WEIGHT_CONFIGS["hybrid_semantic"]]
            ),
            "hybrid_balanced": EnsembleRetriever(
                retrievers=[semantic_retriever, bm25_retriever],
                weights=[WEIGHT_CONFIGS["hybrid_balanced"], 1 - WEIGHT_CONFIGS["hybrid_balanced"]]
            ),
            "hybrid_keyword": EnsembleRetriever(
                retrievers=[semantic_retriever, bm25_retriever],
                weights=[WEIGHT_CONFIGS["hybrid_keyword"], 1 - WEIGHT_CONFIGS["hybrid_keyword"]]
            ),
            "multi_query": multi_query_retriever,
            "expanded_query": EnsembleRetriever(
                retrievers=[semantic_retriever, bm25_retriever],
                weights=[WEIGHT_CONFIGS["hybrid_semantic"], 1 - WEIGHT_CONFIGS["hybrid_semantic"]]
            )
        }
        
        # ì¬ìˆœìœ„í™” ë° ì••ì¶• ì˜µì…˜
        cross_encoder_ret = self.compression_manager.get_cross_encoder_retriever()
        compression_ret = self.compression_manager.get_compression_retriever()
        
        self.rerank_compression_options = {
            "rerank_only": cross_encoder_ret,
            "compress_only": compression_ret,
            "rerank_compress_general": cross_encoder_ret,
            "rerank_compress_specific": compression_ret,
            "rerank_compress_troubleshooting": cross_encoder_ret
        }
    
    def emergency_classifier(self, state: AgentState) -> Dict[str, Any]:
        """ì‘ê¸‰ ìƒí™© ë¶„ë¥˜ ë…¸ë“œ"""
        query = state["query"]
        
        try:
            # ì‘ê¸‰ ìƒí™© ê°ì§€
            emergency_analysis = self.emergency_detector.detect_emergency(query)
            
            print(f"ğŸš¨ ì‘ê¸‰ ìƒí™© ë¶„ì„: {emergency_analysis['priority_level']} "
                  f"(ì ìˆ˜: {emergency_analysis['total_score']})")
            
            if emergency_analysis["is_emergency"]:
                # ì‘ê¸‰ ìƒí™© ì²˜ë¦¬ ëª¨ë“œ
                search_strategy = emergency_analysis["search_strategy"]
                
                return {
                    "is_emergency": True,
                    "emergency_level": emergency_analysis["priority_level"],
                    "emergency_score": emergency_analysis["total_score"],
                    "search_strategy": "troubleshooting",  # ê°•ì œë¡œ ë¬¸ì œí•´ê²° ì „ëµ
                    "search_method": search_strategy["search_method"],
                    "compression_method": search_strategy["compression_method"],
                    "emergency_analysis": emergency_analysis
                }
            else:
                # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ ëª¨ë“œ  
                return {
                    "is_emergency": False,
                    "emergency_level": "NORMAL",
                    "emergency_score": emergency_analysis["total_score"],
                    "emergency_analysis": emergency_analysis
                }
                
        except Exception as e:
            print(f"ì‘ê¸‰ ìƒí™© ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ ì¼ë°˜ ëª¨ë“œë¡œ ì²˜ë¦¬
            return {
                "is_emergency": False,
                "emergency_level": "NORMAL", 
                "emergency_score": 0,
                "emergency_analysis": None
            }
    
    def query_analyzer(self, state: AgentState) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ë¶„ì„ ë…¸ë“œ"""
        query = state["query"]
        is_emergency = state.get("is_emergency", False)
        
        try:
            # ì‘ê¸‰ ìƒí™©ì´ë©´ ì´ë¯¸ ì„¤ì •ëœ ì „ëµ ì‚¬ìš©
            if is_emergency:
                search_strategy = state.get("search_strategy", "troubleshooting")
                search_method = state.get("search_method", "hybrid_keyword")
                compression_method = state.get("compression_method", "rerank_compress_troubleshooting")
                confidence_score = 0.95  # ì‘ê¸‰ ìƒí™©ì€ ë†’ì€ ì‹ ë¢°ë„ë¡œ ì²˜ë¦¬
                
                print(f"ğŸš¨ ì‘ê¸‰ ëª¨ë“œ: {search_strategy} -> {search_method}")
                
                return {
                    "search_strategy": search_strategy,
                    "search_method": search_method,
                    "confidence_score": confidence_score,
                    "compression_method": compression_method
                }
            
            # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
            analysis_chain = self.analysis_prompt | self.llm | StrOutputParser()
            analysis_result = analysis_chain.invoke({"query": query})
            
            # ê²°ê³¼ íŒŒì‹±
            search_strategy = self._extract_field(analysis_result, "ê²€ìƒ‰ ì „ëµ")
            search_method = self._extract_field(analysis_result, "ê²€ìƒ‰ ë°©ë²•")
            confidence_str = self._extract_field(analysis_result, "ì‹ ë¢°ë„")
            
            # ì‹ ë¢°ë„ ì ìˆ˜ ë³€í™˜
            try:
                confidence_score = float(confidence_str)
            except:
                confidence_score = 0.8
            
            # ì¿¼ë¦¬ í™•ì¥ ë° ë‹¤ì¤‘ ì¿¼ë¦¬ ë¡œì§
            original_search_method = search_method
            if any(keyword in query.lower() for keyword in ['êµì²´', 'ë¬¸ì œ', 'ê³ ì¥', 'ì´ìƒ']):
                search_method = "expanded_query"
                print(f"ğŸ”§ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ë°©ë²• ë³€ê²½: {original_search_method} â†’ {search_method}")
            elif len(query) > 20 and '?' in query:
                search_method = "multi_query"
                print(f"ğŸ”§ ë³µì¡í•œ ì§ˆë¬¸ ê°ì§€, ê²€ìƒ‰ ë°©ë²• ë³€ê²½: {original_search_method} â†’ {search_method}")
            
            # ì¬ìˆœìœ„í™”/ì••ì¶• ë°©ë²• ì„ íƒ
            compression_method = self._select_compression_method(search_strategy)
            
            # ê²€ìƒ‰ ì „ëµ ë¡œê·¸ ì¶œë ¥
            print(f"ğŸ“‹ ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼:")
            print(f"   â€¢ ê²€ìƒ‰ ì „ëµ: {search_strategy}")
            print(f"   â€¢ ê²€ìƒ‰ ë°©ë²•: {search_method}")
            print(f"   â€¢ ì‹ ë¢°ë„: {confidence_score}")
            print(f"   â€¢ ì••ì¶• ë°©ë²•: {compression_method}")
            
            return {
                "search_strategy": search_strategy,
                "search_method": search_method,
                "confidence_score": confidence_score,
                "compression_method": compression_method
            }
            
        except Exception as e:
            print(f"ì¿¼ë¦¬ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {
                "search_strategy": "general",
                "search_method": "hybrid_semantic",
                "confidence_score": 0.5,
                "compression_method": "rerank_compress_general"
            }
    
    def search_executor(self, state: AgentState) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì‹¤í–‰ ë…¸ë“œ"""
        query = state["query"]
        search_method = state.get("search_method", "hybrid_semantic")
        compression_method = state.get("compression_method", "rerank_compress_general")
        
        print(f"ğŸ” ê²€ìƒ‰ ì‹¤í–‰ ì‹œì‘:")
        print(f"   â€¢ ì„ íƒëœ ê²€ìƒ‰ ë°©ë²•: {search_method}")
        print(f"   â€¢ ì••ì¶•/ì¬ìˆœìœ„í™” ë°©ë²•: {compression_method}")
        
        try:
            # 1ì°¨ ê²€ìƒ‰ ìˆ˜í–‰
            if search_method == "expanded_query":
                print("ğŸ” í™•ì¥ ì¿¼ë¦¬ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
                from ..tools.search_tools import expanded_query_search
                search_results = expanded_query_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
            elif search_method == "multi_query":
                print("ğŸ” ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
                from ..tools.search_tools import multi_query_search
                search_results = multi_query_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
            else:
                # ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜í–‰
                print(f"ğŸ” ê¸°ë³¸ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘... (ë°©ë²•: {search_method})")
                retriever = self.search_options.get(search_method)
                if retriever:
                    docs = retriever.invoke(query)
                    search_results = [
                        {
                            "content": doc.page_content,
                            "page": doc.metadata.get("page", 0),
                            "source": doc.metadata.get("source", ""),
                            "score": 1.0
                        }
                        for doc in docs[:DEFAULT_TOP_K]
                    ]
                else:
                    print(f"âŒ ê²€ìƒ‰ ë°©ë²• '{search_method}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    search_results = [{"content": "ê²€ìƒ‰ ë°©ë²•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "page": 0, "score": 0.0}]
            
            print(f"ğŸ“Š 1ì°¨ ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            
            # 2ì°¨ ì¬ìˆœìœ„í™”/ì••ì¶• ì ìš©
            if compression_method and compression_method != "none":
                print(f"ğŸ”„ ì¬ìˆœìœ„í™”/ì••ì¶• ì ìš© ì¤‘... (ë°©ë²•: {compression_method})")
                original_count = len(search_results)
                search_results = self._apply_compression(query, search_results, compression_method)
                print(f"âœ… ì¬ìˆœìœ„í™” ì™„ë£Œ: {original_count}ê°œ â†’ {len(search_results)}ê°œ ë¬¸ì„œ")
            else:
                print("â­ï¸  ì¬ìˆœìœ„í™”/ì••ì¶• ê±´ë„ˆëœ€")
            
            # í˜ì´ì§€ ì°¸ì¡° ì¶”ì¶œ
            page_references = list(set([
                result.get("page", 0) for result in search_results if result.get("page", 0) > 0
            ]))
            
            print(f"ğŸ“„ ìµœì¢… ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ ë¬¸ì„œ, {len(page_references)}ê°œ í˜ì´ì§€ ì°¸ì¡°")
            
            return {
                "search_results": search_results,
                "page_references": page_references
            }
            
        except Exception as e:
            print(f"ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return {
                "search_results": [{"content": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "page": 0, "score": 0.0}],
                "page_references": []
            }
    
    def answer_generator(self, state: AgentState) -> Dict[str, Any]:
        """ë‹µë³€ ìƒì„± ë…¸ë“œ"""
        query = state["query"]
        search_results = state.get("search_results", [])
        page_references = state.get("page_references", [])
        is_emergency = state.get("is_emergency", False)
        emergency_level = state.get("emergency_level", "NORMAL")
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (í˜ì´ì§€ ì •ë³´ ê°•í™”)
            context_parts = []
            valid_pages = []
            
            for i, result in enumerate(search_results[:5], 1):
                content = result.get("content", "")
                page = result.get("page", 0)
                score = result.get("score", 0.0)
                
                if page > 0:
                    valid_pages.append(page)
                    context_parts.append(f"[ê²€ìƒ‰ê²°ê³¼ {i}] (í˜ì´ì§€ {page}, ê´€ë ¨ë„: {score:.2f})\n{content}")
                else:
                    context_parts.append(f"[ê²€ìƒ‰ê²°ê³¼ {i}] (ê´€ë ¨ë„: {score:.2f})\n{content}")
            
            context = "\n\n".join(context_parts)
            
            # ì‘ê¸‰ ìƒí™© í”„ë¡¬í”„íŠ¸ ê°•í™”
            emergency_enhancement = ""
            if is_emergency:
                emergency_enhancement = self.emergency_detector.get_emergency_prompt_enhancement(emergency_level)
                context = emergency_enhancement + "\n\n" + context
                print(f"ğŸš¨ ì‘ê¸‰ ë‹µë³€ ìƒì„± ëª¨ë“œ: {emergency_level}")
            
            # í˜ì´ì§€ ì°¸ì¡° ì •ë³´ ì¶”ê°€
            page_info = ""
            if valid_pages:
                unique_pages = sorted(list(set(valid_pages)))
                if len(unique_pages) == 1:
                    page_info = f"\n\nğŸ“š ì°¸ê³  í˜ì´ì§€: {unique_pages[0]}"
                elif len(unique_pages) <= 3:
                    page_info = f"\n\nğŸ“š ì°¸ê³  í˜ì´ì§€: {', '.join(map(str, unique_pages))}"
                else:
                    page_info = f"\n\nğŸ“š ì£¼ìš” ì°¸ê³  í˜ì´ì§€: {', '.join(map(str, unique_pages[:3]))} ì™¸"
            
            # Few-shot í”„ë¡¬í”„íŠ¸ë¡œ ë‹µë³€ ìƒì„±
            answer_chain = self.answer_prompt | self.llm | StrOutputParser()
            final_answer = answer_chain.invoke({
                "query": query,
                "context": context
            })
            
            # í˜ì´ì§€ ì •ë³´ê°€ ë‹µë³€ì— ì—†ìœ¼ë©´ ì¶”ê°€
            if page_info and "ğŸ“š" not in final_answer:
                final_answer += page_info
            
            # ì‘ê¸‰ ìƒí™© ë“±ê¸‰ í‘œì‹œë¥¼ ë‹µë³€ ì²« ì¤„ì— ì¶”ê°€
            emergency_header = ""
            if is_emergency:
                # ì‘ê¸‰ ìƒí™© í—¤ë” ìƒì„±
                emergency_icons = {
                    "CRITICAL": "ğŸ”¥",
                    "HIGH": "ğŸš¨", 
                    "MEDIUM": "âš ï¸",
                    "LOW": "ğŸ”"
                }
                icon = emergency_icons.get(emergency_level, "ğŸš¨")
                emergency_header = f"{icon} **{emergency_level} ì‘ê¸‰ ìƒí™©**\n\n"
                
                # ì‘ê¸‰ ìƒí™©ì—ì„œëŠ” ì‹ ë¢°ë„ í‰ê°€ ê°„ì†Œí™” (ì†ë„ ìš°ì„ )
                confidence_percentage = 85.0  # ì‘ê¸‰ ìƒí™© ê¸°ë³¸ ì‹ ë¢°ë„
                reliability_grade = "ë†’ìŒ (A)"
                
                # ì‘ê¸‰ ìƒí™© ê²½ê³  ì¶”ê°€
                emergency_warning = f"\n\nğŸš¨ **ì‘ê¸‰ ìƒí™© ({emergency_level})**"
                if emergency_level == "CRITICAL":
                    emergency_warning += "\nâš ï¸ ìƒëª… ìœ„í—˜ ìƒí™©ì…ë‹ˆë‹¤. ì¦‰ì‹œ ì¡°ì¹˜í•˜ê³  119ì— ì‹ ê³ í•˜ì„¸ìš”."
                elif emergency_level == "HIGH":
                    emergency_warning += "\nâš ï¸ ì¦‰ì‹œ ì•ˆì „ ì¡°ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì „ë¬¸ê°€ì—ê²Œ ì—°ë½í•˜ì„¸ìš”."
                else:
                    emergency_warning += "\nâš ï¸ ì‹ ì†í•œ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤."
                
                final_answer = emergency_header + final_answer + emergency_warning
            else:
                # ì¼ë°˜ ì§ˆë¬¸ í—¤ë” ìƒì„±
                emergency_header = "ğŸ“ **ì¼ë°˜ ì§ˆë¬¸**\n\n"
                
                # ì¼ë°˜ ìƒí™© ì‹ ë¢°ë„ í‰ê°€
                evaluation = self.answer_evaluator.evaluate_answer(query, final_answer, search_results)
                confidence_percentage = evaluation['percentage']
                reliability_grade = evaluation['reliability_grade']
                
                final_answer = emergency_header + final_answer
            
            # ì‹ ë¢°ë„ ì •ë³´ë¥¼ ë‹µë³€ì— ì¶”ê°€
            confidence_info = f"\n\nğŸ” **ë‹µë³€ ì‹ ë¢°ë„**: {confidence_percentage}% ({reliability_grade})"
            
            # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì¶”ê°€ ì•ˆë‚´ (ì‘ê¸‰ ìƒí™©ì´ ì•„ë‹ ë•Œë§Œ)
            if not is_emergency:
                if confidence_percentage >= 80:
                    confidence_info += "\nâœ… ë†’ì€ ì‹ ë¢°ë„ì˜ ë‹µë³€ì…ë‹ˆë‹¤."
                elif confidence_percentage >= 60:
                    confidence_info += "\nâš ï¸ ì¶”ê°€ í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                else:
                    confidence_info += "\nâŒ ì „ë¬¸ê°€ ìƒë‹´ì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤."
            
            final_answer_with_confidence = final_answer + confidence_info
            
            return {
                "final_answer": final_answer_with_confidence,
                "confidence_score": confidence_percentage / 100,
                "evaluation_details": evaluation if not is_emergency else None
            }
            
        except Exception as e:
            print(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {"final_answer": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}
    
    def driving_context_processor(self, state: AgentState) -> Dict[str, Any]:
        """ì£¼í–‰ ì¤‘ ìƒí™© ê°ì§€ ë° ë‹µë³€ ì••ì¶• ë…¸ë“œ"""
        query = state["query"]
        original_answer = state.get("final_answer", "")
        
        # Emergency ì •ë³´ ì°¸ì¡° (ì •ë³´ ê³µìœ  ìµœì í™”)
        is_emergency = state.get("is_emergency", False)
        emergency_level = state.get("emergency_level", "NORMAL")
        
        try:
            print("ğŸš— ì£¼í–‰ ìƒí™© ë¶„ì„ ì¤‘...")
            
            # 1. ì£¼í–‰ ì¤‘ ìƒí™© ê°ì§€ (Emergency ì •ë³´ í™œìš©)
            if is_emergency and emergency_level in ["CRITICAL", "HIGH"]:
                # ì‘ê¸‰ ìƒí™©ì´ë©´ ì£¼í–‰ ì¤‘ìœ¼ë¡œ ê°€ì •í•˜ê³  ê°„ì†Œí™”ëœ ë¶„ì„
                print("âš¡ ì‘ê¸‰ ìƒí™© ê°ì§€ë¨ - ì£¼í–‰ ì¤‘ìœ¼ë¡œ ê°€ì •")
                is_driving = True
                confidence = 0.95
                urgency_level = "immediate" if emergency_level == "CRITICAL" else "urgent"
                driving_analysis = {
                    "is_driving": True,
                    "confidence": confidence,
                    "urgency_level": urgency_level,
                    "compression_needed": True,
                    "driving_indicators": [f"ì‘ê¸‰ìƒí™©({emergency_level})"]
                }
            else:
                # ì¼ë°˜ ìƒí™©ì—ì„œë§Œ ìƒì„¸ ì£¼í–‰ ë¶„ì„ ìˆ˜í–‰
                driving_analysis = self.driving_detector.detect_driving_context(query)
                is_driving = driving_analysis["is_driving"]
                confidence = driving_analysis["confidence"]
                urgency_level = driving_analysis["urgency_level"]
            
            print(f"ğŸš— ì£¼í–‰ ìƒí™© ë¶„ì„ ê²°ê³¼:")
            print(f"   â€¢ ì£¼í–‰ ì¤‘ ì—¬ë¶€: {is_driving} (ì‹ ë¢°ë„: {confidence:.2f})")
            print(f"   â€¢ ê¸´ê¸‰ë„: {urgency_level}")
            
            if driving_analysis["driving_indicators"]:
                indicators = ", ".join(driving_analysis["driving_indicators"])
                print(f"   â€¢ ê°ì§€ëœ ì§€í‘œ: {indicators}")
            
            # 2. ì£¼í–‰ ì¤‘ì´ë©´ ë‹µë³€ ì••ì¶•
            if is_driving and driving_analysis["compression_needed"]:
                print("ğŸ“± ì£¼í–‰ ì¤‘ ëª¨ë“œ - ë‹µë³€ ì••ì¶• ì¤‘...")
                
                compression_result = self.driving_detector.compress_answer(
                    original_answer, query, urgency_level
                )
                
                compressed_answer = compression_result["compressed_answer"]
                compression_ratio = compression_result["compression_ratio"]
                
                print(f"âœ… ë‹µë³€ ì••ì¶• ì™„ë£Œ (ì••ì¶•ë¥ : {compression_ratio:.1%})")
                
                # ì£¼í–‰ ì¤‘ ì•ˆì „ ë©”ì‹œì§€ ì¶”ê°€
                if urgency_level == "immediate":
                    safety_message = "\n\nğŸ›‘ **ì¦‰ì‹œ ì•ˆì „í•œ ê³³ì— ì •ì°¨í•˜ì„¸ìš”**"
                elif urgency_level == "urgent":
                    safety_message = "\n\nâš ï¸ **ê°€ëŠ¥í•œ ë¹¨ë¦¬ ì•ˆì „í•œ ê³³ì—ì„œ í™•ì¸í•˜ì„¸ìš”**"
                else:
                    safety_message = "\n\nğŸ“‹ **ì£¼í–‰ í›„ ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”**"
                
                final_compressed = compressed_answer + safety_message
                
                return {
                    "is_driving": True,
                    "driving_confidence": confidence,
                    "driving_indicators": driving_analysis["driving_indicators"],
                    "driving_urgency": urgency_level,
                    "compression_needed": True,
                    "compressed_answer": final_compressed,
                    "final_answer": final_compressed  # ìµœì¢… ë‹µë³€ì„ ì••ì¶•ëœ ë²„ì „ìœ¼ë¡œ ëŒ€ì²´
                }
            
            else:
                # ì£¼í–‰ ì¤‘ì´ ì•„ë‹ˆê±°ë‚˜ ì••ì¶•ì´ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš°
                print("ğŸ  ì¼ë°˜ ëª¨ë“œ - ì›ë³¸ ë‹µë³€ ìœ ì§€")
                
                return {
                    "is_driving": False,
                    "driving_confidence": confidence,
                    "driving_indicators": driving_analysis.get("driving_indicators", []),
                    "driving_urgency": "normal",
                    "compression_needed": False,
                    "compressed_answer": "",
                    "final_answer": original_answer  # ì›ë³¸ ë‹µë³€ ìœ ì§€
                }
                
        except Exception as e:
            print(f"ì£¼í–‰ ìƒí™© ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë‹µë³€ ìœ ì§€
            return {
                "is_driving": False,
                "driving_confidence": 0.0,
                "driving_indicators": [],
                "driving_urgency": "normal",
                "compression_needed": False,
                "compressed_answer": "",
                "final_answer": original_answer
            }
    
    def _extract_field(self, text: str, field_name: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • í•„ë“œ ê°’ ì¶”ì¶œ"""
        pattern = rf"{field_name}:\s*(.+?)(?:\n|$)"
        match = re.search(pattern, text)
        if match:
            return match.group(1).strip()
        return "general" if "ì „ëµ" in field_name else "hybrid_semantic"
    
    def _select_compression_method(self, search_strategy: str) -> str:
        """ê²€ìƒ‰ ì „ëµì— ë”°ë¥¸ ì••ì¶• ë°©ë²• ì„ íƒ"""
        compression_map = {
            "troubleshooting": "rerank_compress_troubleshooting",
            "specific": "rerank_compress_specific",
            "general": "rerank_compress_general"
        }
        return compression_map.get(search_strategy, "rerank_compress_general")
    
    def _apply_compression(self, query: str, search_results: List[Dict], compression_method: str) -> List[Dict]:
        """ì••ì¶•/ì¬ìˆœìœ„í™” ì ìš©"""
        try:
            retriever = self.rerank_compression_options.get(compression_method)
            if retriever:
                # ì••ì¶• ê²€ìƒ‰ ìˆ˜í–‰
                if compression_method.startswith("rerank_compress"):
                    from ..tools.search_tools import cross_encoder_rerank_search
                    return cross_encoder_rerank_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
                else:
                    from ..tools.search_tools import contextual_compression_search
                    return contextual_compression_search.invoke({"query": query, "top_k": DEFAULT_TOP_K})
            
        except Exception as e:
            print(f"ì••ì¶• ì ìš© ì˜¤ë¥˜: {str(e)}")
        
        return search_results
    
    def create_graph(self) -> StateGraph:
        """LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(AgentState)
        
        # ë…¸ë“œ ì¶”ê°€ (ì‘ê¸‰ ë¶„ë¥˜ ë…¸ë“œ ì¶”ê°€)
        workflow.add_node("emergency_classifier", self.emergency_classifier)
        workflow.add_node("query_analyzer", self.query_analyzer)
        workflow.add_node("search_executor", self.search_executor)
        workflow.add_node("answer_generator", self.answer_generator)
        workflow.add_node("driving_context_processor", self.driving_context_processor)
        
        # ì—£ì§€ ì¶”ê°€ (ì‘ê¸‰ ë¶„ë¥˜ -> ì¿¼ë¦¬ ë¶„ì„ -> ê²€ìƒ‰ -> ë‹µë³€ -> ì£¼í–‰ ìƒí™© ì²˜ë¦¬)
        workflow.set_entry_point("emergency_classifier")
        workflow.add_edge("emergency_classifier", "query_analyzer")
        workflow.add_edge("query_analyzer", "search_executor")
        workflow.add_edge("search_executor", "answer_generator")
        workflow.add_edge("answer_generator", "driving_context_processor")
        workflow.add_edge("driving_context_processor", END)
        
        return workflow.compile()
    
    def query(self, user_query: str, callbacks=None) -> str:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬"""
        try:
            graph = self.create_graph()
            
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = {
                "messages": [],
                "query": user_query,
                "search_results": [],
                "context": "",
                "final_answer": "",
                "search_strategy": "",
                "search_method": "",
                "confidence_score": 0.0,
                "page_references": [],
                "need_clarification": False,
                # ì‘ê¸‰ ìƒí™© ê´€ë ¨ ì´ˆê¸°ê°’
                "is_emergency": False,
                "emergency_level": "NORMAL",
                "emergency_score": 0.0,
                "emergency_analysis": {},
                "compression_method": "",
                # ì£¼í–‰ ìƒí™© ê´€ë ¨ ì´ˆê¸°ê°’
                "is_driving": False,
                "driving_confidence": 0.0,
                "driving_indicators": [],
                "driving_urgency": "normal",
                "compression_needed": False,
                "compressed_answer": ""
            }
            
            # ì½œë°±ì´ ìˆìœ¼ë©´ ì„¤ì •ì— í¬í•¨
            config = {}
            if callbacks:
                config["callbacks"] = callbacks
            
            # ê·¸ë˜í”„ ì‹¤í–‰
            result = graph.invoke(initial_state, config=config)
            
            return result.get("final_answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            return f"ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
