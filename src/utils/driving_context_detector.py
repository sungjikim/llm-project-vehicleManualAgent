"""
ì£¼í–‰ ì¤‘ ìƒí™© ê°ì§€ ë° ë‹µë³€ ì••ì¶• ì‹œìŠ¤í…œ
"""

import re
from typing import Dict, Any, List, Optional
from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI


class DrivingContextAnalysis(BaseModel):
    """ì£¼í–‰ ìƒí™© ë¶„ì„ ê²°ê³¼"""
    is_driving: bool = Field(description="ì£¼í–‰ ì¤‘ ì—¬ë¶€")
    confidence: float = Field(description="íŒë‹¨ ì‹ ë¢°ë„ (0-1)")
    driving_indicators: List[str] = Field(description="ì£¼í–‰ ì¤‘ì„ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œë“¤")
    urgency_level: str = Field(description="ê¸´ê¸‰ë„ ìˆ˜ì¤€: immediate, urgent, normal")
    compression_needed: bool = Field(description="ë‹µë³€ ì••ì¶• í•„ìš” ì—¬ë¶€")


class CompressedAnswer(BaseModel):
    """ì••ì¶•ëœ ë‹µë³€ êµ¬ì¡°"""
    key_action: str = Field(description="í•µì‹¬ í–‰ë™ ì§€ì¹¨")
    safety_warning: Optional[str] = Field(description="ì•ˆì „ ê²½ê³  (í•„ìš”ì‹œ)")
    quick_steps: List[str] = Field(description="ê°„ë‹¨í•œ ë‹¨ê³„ë³„ ì§€ì¹¨ (ìµœëŒ€ 3ë‹¨ê³„)")
    follow_up: Optional[str] = Field(description="ì£¼í–‰ í›„ ìƒì„¸ í™•ì¸ ì‚¬í•­")


class DrivingContextDetector:
    """ì£¼í–‰ ì¤‘ ìƒí™© ê°ì§€ ë° ë‹µë³€ ì••ì¶•ê¸°"""
    
    def __init__(self, llm_model: str = "gpt-4o-mini", temperature: float = 0):
        self.llm = ChatOpenAI(model=llm_model, temperature=temperature)
        
        # êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ LLM ì„¤ì •
        self.structured_analyzer = self.llm.with_structured_output(DrivingContextAnalysis)
        self.structured_compressor = self.llm.with_structured_output(CompressedAnswer)
        
        # ì£¼í–‰ ì¤‘ ìƒí™© ê°ì§€ í”„ë¡¬í”„íŠ¸
        self.driving_detection_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë°œí™”ì—ì„œ í˜„ì¬ ì£¼í–‰ ì¤‘ì¸ì§€ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼í–‰ ì¤‘ ìƒí™©ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œë“¤:

1. **ëª…ì‹œì  ì£¼í–‰ í‘œí˜„** (ê°€ì¤‘ì¹˜: ë†’ìŒ)
   - ì§ì ‘ì : "ìš´ì „ ì¤‘", "ì£¼í–‰ ì¤‘", "ì°¨ ì•ˆì—ì„œ", "ë„ë¡œì—ì„œ", "í•¸ë“¤ ì¡ê³ "
   - ì´ë™ ê´€ë ¨: "ì¶œê·¼ ì¤‘", "í‡´ê·¼ ì¤‘", "ì´ë™ ì¤‘", "ê°€ëŠ” ê¸¸", "ì˜¤ëŠ” ê¸¸"
   - ë„ë¡œ ìƒí™©: "ê³ ì†ë„ë¡œì—ì„œ", "ì‹œë‚´ ì£¼í–‰", "êµí†µì²´ì¦ ì¤‘", "ì‹ í˜¸ ëŒ€ê¸°"

2. **ì‹œê°„ì  ê¸´ê¸‰ì„±** (ê°€ì¤‘ì¹˜: ì¤‘ê°„)
   - ì¦‰ì‹œì„±: "ì§€ê¸ˆ", "í˜„ì¬", "ë°”ë¡œ", "ì¦‰ì‹œ", "ë‹¹ì¥", "ë¹¨ë¦¬"
   - ê¸‰ë°•í•¨: "ê°‘ìê¸°", "ë°©ê¸ˆ", "ë§‰", "ê¸‰í•˜ê²Œ", "ì„œë‘˜ëŸ¬", "ê¸´ê¸‰í•˜ê²Œ"
   - ì‹¤ì‹œê°„: "ì‹¤ì‹œê°„", "ë¼ì´ë¸Œ", "ê³§ë°”ë¡œ", "ì‹ ì†íˆ"

3. **ìƒí™©ì  ë§¥ë½** (ê°€ì¤‘ì¹˜: ë‚®ìŒ)
   - ì§„í–‰ ìƒí™©: "~í•˜ê³  ìˆëŠ”ë°", "~ì¤‘ì¸ë°", "~í•˜ë©´ì„œ", "~í•˜ëŠ” ë™ì•ˆ"
   - í˜„ì¬ ìƒíƒœ: "~í•˜ë‹¤ê°€", "~í•˜ë˜ ì¤‘", "~ì§„í–‰ ì¤‘"

4. **ìœ„ì¹˜/ì´ë™ ê´€ë ¨** (ê°€ì¤‘ì¹˜: ì¤‘ê°„)
   - ë„ë¡œ: "ê¸¸ì—ì„œ", "ë„ë¡œ ìœ„", "ì°¨ì„ ", "í„°ë„ ì•ˆ", "ë‹¤ë¦¬ ìœ„"
   - ì‹œì„¤: "í†¨ê²Œì´íŠ¸", "íœ´ê²Œì†Œ", "ì£¼ìœ ì†Œ", "ì •ë¹„ì†Œ ê°€ëŠ”"
   - ëª©ì ì§€: "íšŒì‚¬ ê°€ëŠ”", "ì§‘ ê°€ëŠ”", "ëª©ì ì§€ í–¥í•´"

5. **ì°¨ëŸ‰ ìƒíƒœ/ë™ì‘** (ê°€ì¤‘ì¹˜: ì¤‘ê°„)
   - ì¡°ì‘: "ì‹œë™ ê±¸ê³ ", "ê¸°ì–´ ë„£ê³ ", "ë¸Œë ˆì´í¬ ë°Ÿê³ ", "ì•¡ì…€ ë°Ÿê³ "
   - ìƒíƒœ: "ì£¼ì°¨ ì¤‘", "ì •ì°¨ ì¤‘", "í›„ì§„ ì¤‘", "íšŒì „ ì¤‘", "ì¶”ì›” ì¤‘"

6. **ìŒì„±/í•¸ì¦ˆí”„ë¦¬ ë‹¨ì„œ** (ê°€ì¤‘ì¹˜: ë†’ìŒ)
   - ìŒì„± ì…ë ¥: "ìŒì„±ìœ¼ë¡œ", "ë§ë¡œ", "í•¸ì¦ˆí”„ë¦¬", "ë¸”ë£¨íˆ¬ìŠ¤"
   - ì†Œë¦¬: "ì†Œë¦¬ ë‚´ì„œ", "í° ì†Œë¦¬ë¡œ", "ìŒì„± ëª…ë ¹", "ëŒ€í™” ì¤‘"

íŒë‹¨ ê¸°ì¤€:
- ëª…í™•í•œ ì£¼í–‰ ì¤‘ í‘œí˜„ + ìŒì„± ë‹¨ì„œ: 95% ì´ìƒ ì‹ ë¢°ë„
- ëª…í™•í•œ ì£¼í–‰ ì¤‘ í‘œí˜„: 85-95% ì‹ ë¢°ë„
- ê°•í•œ ì‹œê°„ì  ê¸´ê¸‰ì„± + ìœ„ì¹˜ ì •ë³´: 70-85% ì‹ ë¢°ë„
- ì°¨ëŸ‰ ìƒíƒœ/ë™ì‘ í‘œí˜„: 60-80% ì‹ ë¢°ë„
- ìƒí™©ì  ë§¥ë½ë§Œ: 40-60% ì‹ ë¢°ë„
- ì¼ë°˜ì  ì§ˆë¬¸: 30% ë¯¸ë§Œ ì‹ ë¢°ë„

ê¸´ê¸‰ë„ ìˆ˜ì¤€:
- immediate: ì¦‰ì‹œ ëŒ€ì‘ í•„ìš” (ì•ˆì „ ìœ„í—˜, ìƒëª… ìœ„í—˜)
- urgent: ë¹ ë¥¸ ëŒ€ì‘ í•„ìš” (ê¸°ëŠ¥ ë¬¸ì œ, ì£¼í–‰ ë°©í•´)
- normal: ì¼ë°˜ì  ë¬¸ì˜ (ì •ë³´ ìš”ì²­)"""),
            ("human", "ì‚¬ìš©ì ë°œí™”: {query}")
        ])
        
        # ë‹µë³€ ì••ì¶• í”„ë¡¬í”„íŠ¸
        self.answer_compression_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì£¼í–‰ ì¤‘ì¸ ìš´ì „ìë¥¼ ìœ„í•´ ë‹µë³€ì„ ì••ì¶•í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì••ì¶• ì›ì¹™:
1. ì•ˆì „ ìµœìš°ì„ : ì£¼í–‰ì— ë°©í•´ë˜ì§€ ì•Šë„ë¡
2. í•µì‹¬ë§Œ ì „ë‹¬: ê°€ì¥ ì¤‘ìš”í•œ 1-2ê°€ì§€ í–‰ë™ë§Œ
3. ê°„ê²°í•œ í‘œí˜„: í•œ ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ì „ë‹¬
4. ë‹¨ê³„ë³„ ìµœì†Œí™”: ìµœëŒ€ 3ë‹¨ê³„ê¹Œì§€ë§Œ
5. ì‹œê°ì  ì£¼ì˜ ìµœì†Œí™”: ê¸´ í…ìŠ¤íŠ¸ ê¸ˆì§€

ì••ì¶• ê¸°ì¤€:
- ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”: í•µì‹¬ í–‰ë™ 1ê°œ + ì•ˆì „ ê²½ê³ 
- ë¹ ë¥¸ ëŒ€ì‘ í•„ìš”: í•µì‹¬ í–‰ë™ + ê°„ë‹¨ ë‹¨ê³„ 2ê°œ
- ì¼ë°˜ ìƒí™©: í•µì‹¬ + ë‹¨ê³„ 3ê°œ + í›„ì† ì¡°ì¹˜

ê¸ˆì§€ ì‚¬í•­:
- ê¸´ ì„¤ëª…ë¬¸
- ë³µì¡í•œ ì ˆì°¨
- í˜ì´ì§€ ë²ˆí˜¸ë‚˜ ìƒì„¸ ì°¸ì¡°
- ì‹ ë¢°ë„ ì •ë³´ (ì£¼ì˜ ë¶„ì‚°)"""),
            ("human", """ì›ë³¸ ë‹µë³€: {original_answer}
ì‚¬ìš©ì ì§ˆë¬¸: {query}
ê¸´ê¸‰ë„: {urgency_level}

ìœ„ ë‹µë³€ì„ ì£¼í–‰ ì¤‘ì¸ ìš´ì „ìì—ê²Œ ì í•©í•˜ë„ë¡ ì••ì¶•í•´ì£¼ì„¸ìš”.""")
        ])
        
        # ì²´ì¸ êµ¬ì„±
        self.detection_chain = self.driving_detection_prompt | self.structured_analyzer
        self.compression_chain = self.answer_compression_prompt | self.structured_compressor
        
        # ì£¼í–‰ ì¤‘ í‚¤ì›Œë“œ íŒ¨í„´
        self.driving_keywords = {
            "explicit": [  # ëª…ì‹œì  ì£¼í–‰ í‘œí˜„
                r"ìš´ì „\s*ì¤‘", r"ì£¼í–‰\s*ì¤‘", r"ì°¨\s*ì•ˆì—ì„œ", r"ë„ë¡œì—ì„œ",
                r"ìš´ì „í•˜ë©´ì„œ", r"ì£¼í–‰í•˜ë©´ì„œ", r"ì°¨ì—ì„œ", r"ìš´ì „ì„ì—ì„œ",
                r"í•¸ë“¤\s*ì¡ê³ ", r"ë“œë¼ì´ë¸Œ\s*ì¤‘", r"ì¶œê·¼\s*ì¤‘", r"í‡´ê·¼\s*ì¤‘",
                r"ì´ë™\s*ì¤‘", r"ê°€ëŠ”\s*ê¸¸", r"ì˜¤ëŠ”\s*ê¸¸", r"ë“œë¼ì´ë¹™\s*ì¤‘",
                r"ê³ ì†ë„ë¡œì—ì„œ", r"ì‹œë‚´\s*ì£¼í–‰", r"êµí†µì²´ì¦\s*ì¤‘", r"ì‹ í˜¸\s*ëŒ€ê¸°",
                r"ì£¼ì°¨ì¥\s*ì°¾ëŠ”", r"ê¸¸\s*ì°¾ëŠ”", r"ë‚´ë¹„\s*ì¼œê³ ", r"GPS\s*ë³´ë©´ì„œ"
            ],
            "temporal": [  # ì‹œê°„ì  ê¸´ê¸‰ì„±
                r"ì§€ê¸ˆ", r"í˜„ì¬", r"ë°”ë¡œ", r"ì¦‰ì‹œ", r"ë‹¹ì¥", r"ë¹¨ë¦¬",
                r"ê°‘ìê¸°", r"ë°©ê¸ˆ", r"ë§‰", r"ê¸ˆë°©", r"ê¸‰í•˜ê²Œ", r"ì„œë‘˜ëŸ¬",
                r"ê¸´ê¸‰í•˜ê²Œ", r"ì‘ê¸‰", r"ìœ„ê¸‰", r"ê¸‰íˆ", r"ì–¼ë¥¸", r"ì‹ ì†íˆ",
                r"ê³§ë°”ë¡œ", r"ì§ì ‘", r"ì‹¤ì‹œê°„", r"ë¼ì´ë¸Œ"
            ],
            "situational": [  # ìƒí™©ì  ë§¥ë½
                r"~í•˜ê³ \s*ìˆëŠ”ë°", r"~ì¤‘ì¸ë°", r"~í•˜ë©´ì„œ", r"~í•˜ëŠ”\s*ë™ì•ˆ",
                r"~í• \s*ë•Œ", r"~í•˜ë ¤ê³ \s*í•˜ëŠ”ë°", r"~í•˜ê³ \s*ìˆì–´ì„œ",
                r"~í•˜ëŠ”\s*ìƒí™©", r"~í•˜ëŠ”\s*ì™€ì¤‘", r"~í•˜ë‹¤ê°€", r"~í•˜ë˜\s*ì¤‘",
                r"~í•˜ê³ \s*ê³„ì‹ ", r"~í•˜ì‹œëŠ”\s*ì¤‘", r"~ì§„í–‰\s*ì¤‘"
            ],
            "location": [  # ìœ„ì¹˜/ì´ë™ ê´€ë ¨
                r"ê¸¸ì—ì„œ", r"ë„ë¡œ\s*ìœ„", r"ì°¨ì„ ", r"í„°ë„\s*ì•ˆ", r"ë‹¤ë¦¬\s*ìœ„",
                r"ê³ ê°€ë„ë¡œ", r"ì–¸ë”íŒ¨ìŠ¤", r"ë¨í”„", r"í†¨ê²Œì´íŠ¸", r"íœ´ê²Œì†Œ",
                r"ì£¼ìœ ì†Œ", r"ì„¸ì°¨ì¥", r"ì •ë¹„ì†Œ\s*ê°€ëŠ”", r"ì„œë¹„ìŠ¤ì„¼í„°\s*ê°€ëŠ”",
                r"ëª©ì ì§€\s*í–¥í•´", r"íšŒì‚¬\s*ê°€ëŠ”", r"ì§‘\s*ê°€ëŠ”", r"ë§ˆíŠ¸\s*ê°€ëŠ”"
            ],
            "vehicle_state": [  # ì°¨ëŸ‰ ìƒíƒœ/ë™ì‘ ê´€ë ¨
                r"ì‹œë™\s*ê±¸ê³ ", r"ê¸°ì–´\s*ë„£ê³ ", r"ì•¡ì…€\s*ë°Ÿê³ ", r"ë¸Œë ˆì´í¬\s*ë°Ÿê³ ",
                r"í´ëŸ¬ì¹˜\s*ë°Ÿê³ ", r"í•¸ë“œë¸Œë ˆì´í¬", r"ì‚¬ì´ë“œë¸Œë ˆì´í¬", r"í›„ì§„\s*ì¤‘",
                r"ì£¼ì°¨\s*ì¤‘", r"ìœ í„´\s*ì¤‘", r"íšŒì „\s*ì¤‘", r"ì¶”ì›”\s*ì¤‘",
                r"ì •ì°¨\s*ì¤‘", r"ì‹ í˜¸\s*ê¸°ë‹¤ë¦¬ëŠ”", r"ëŒ€ê¸°\s*ì¤‘", r"ë©ˆì¶°\s*ìˆëŠ”"
            ],
            "emergency_malfunction": [  # ì‘ê¸‰ ê³ ì¥ ìƒí™© (ë†’ì€ ê°€ì¤‘ì¹˜)
                r"ë¸Œë ˆì´í¬.*?ì•ˆ.*?(ë“¤ì–´|ë™ì‘|ì‘ë™|ë©ˆì¶¤)", r"ë¸Œë ˆì´í¬.*?(ê³ ì¥|ì´ìƒ|ë¬¸ì œ)",
                r"ë¸Œë ˆì´í¬.*?(ë”±ë”±|ë¬´ê±°ì›Œ|ì†Œë¦¬|ì§„ë™|ëŒë ¤)", r"ë¸Œë ˆì´í¬.*?í˜ë‹¬",
                r"ì—”ì§„.*?ì•ˆ.*?(ëŒì•„|ì¼œì ¸|ì‹œë™)", r"ì—”ì§„.*?(ê³ ì¥|ì´ìƒ|ë¬¸ì œ|êº¼ì§)",
                r"í•¸ë“¤.*?ì•ˆ.*?(ëŒì•„|ì›€ì§)", r"í•¸ë“¤.*?(ê³ ì¥|ì´ìƒ|ë¬´ê±°ì›Œ)",
                r"ê°€ì†.*?ì•ˆ.*?(ë¼|ë˜)", r"ì•¡ì…€.*?ì•ˆ.*?(ë°Ÿí˜€|ëˆŒëŸ¬)",
                r"ë™ì‘.*?ì•ˆ.*?í•´", r"ì‘ë™.*?ì•ˆ.*?í•´", r"ì•ˆ.*?ë“¤ì–´", r"ì•ˆ.*?ë©ˆì¶°",
                r"ì•ˆ.*?ëŒì•„", r"ì•ˆ.*?ì¼œì ¸", r"ì•ˆ.*?ì›€ì§", r"ê³ ì¥.*?ë‚˜",
                r"ì´ìƒ.*?(í•´|ì†Œë¦¬|ì§„ë™)", r"ë¬¸ì œ.*?ìƒê²¨", r"ë©ˆì¶”ì§€.*?ì•Šì•„",
                r"ì‘ë‹µ.*?ì—†ì–´", r"ë°˜ì‘.*?ì—†ì–´", r"ë¨¹í†µ", r"ì£½ì–´ë²„ë ¤",
                r"í•„ìš”.*?í•œë°.*?ì•ˆ.*?ë¼", r"ë°Ÿì•„ë„.*?ì•ˆ", r"ëˆŒëŸ¬ë„.*?ì•ˆ",
                r"ì—ì„œ.*?ì†Œë¦¬", r"ì—ì„œ.*?ì§„ë™", r"ì—ì„œ.*?ì´ìƒ"
            ],
            "audio_cues": [  # ìŒì„±/ì†Œë¦¬ ê´€ë ¨ (í•¸ì¦ˆí”„ë¦¬ í™˜ê²½)
                r"ìŒì„±\s*ìœ¼ë¡œ", r"ë§ë¡œ", r"ì†Œë¦¬\s*ë‚´ì„œ", r"í°\s*ì†Œë¦¬ë¡œ",
                r"í•¸ì¦ˆí”„ë¦¬", r"ë¸”ë£¨íˆ¬ìŠ¤", r"ìŠ¤í”¼ì»¤", r"ë§ˆì´í¬",
                r"ìŒì„±\s*ì¸ì‹", r"ìŒì„±\s*ëª…ë ¹", r"ë§í•˜ê¸°", r"ëŒ€í™”\s*ì¤‘",
                r"ì—°ê²°í•´ì„œ", r"ë¬¼ì–´ë³´ëŠ”ë°", r"ì§ˆë¬¸í•˜ëŠ”ë°"
            ]
        }
    
    def detect_driving_context(self, query: str) -> Dict[str, Any]:
        """ì£¼í–‰ ì¤‘ ìƒí™© ê°ì§€"""
        try:
            # í‚¤ì›Œë“œ ê¸°ë°˜ ì‚¬ì „ ë¶„ì„
            keyword_score = self._calculate_keyword_score(query)
            
            # LLM ê¸°ë°˜ ìƒì„¸ ë¶„ì„ (í‚¤ì›Œë“œ ì ìˆ˜ê°€ ì¼ì • ì´ìƒì¼ ë•Œë§Œ)
            if keyword_score > 0.15:  # ì„ê³„ê°’ì„ ë‚®ì¶°ì„œ ë” ë§ì€ ê²½ìš°ì— LLM ë¶„ì„ ìˆ˜í–‰
                analysis = self.detection_chain.invoke({"query": query})
                
                # í‚¤ì›Œë“œ ì ìˆ˜ì™€ LLM ë¶„ì„ ê²°ê³¼ ê²°í•© (í‚¤ì›Œë“œì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
                final_confidence = (keyword_score * 0.6 + analysis.confidence * 0.4)
                
                # í‚¤ì›Œë“œ ì ìˆ˜ê°€ ë†’ìœ¼ë©´ LLMì´ ë°˜ëŒ€í•´ë„ ì£¼í–‰ìœ¼ë¡œ íŒë‹¨
                is_driving_decision = (
                    (keyword_score > 0.4) or  # í‚¤ì›Œë“œ ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ë¬´ì¡°ê±´ ì£¼í–‰
                    (analysis.is_driving and final_confidence > 0.45)  # ì„ê³„ê°’ ì¡°ì •
                )
                
                return {
                    "is_driving": is_driving_decision,
                    "confidence": final_confidence,
                    "driving_indicators": analysis.driving_indicators,
                    "urgency_level": analysis.urgency_level,
                    "compression_needed": analysis.compression_needed,
                    "keyword_score": keyword_score,
                    "analysis": analysis
                }
            else:
                # í‚¤ì›Œë“œ ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ì£¼í–‰ ì¤‘ì´ ì•„ë‹Œ ê²ƒìœ¼ë¡œ íŒë‹¨
                return {
                    "is_driving": False,
                    "confidence": 1.0 - keyword_score,
                    "driving_indicators": [],
                    "urgency_level": "normal",
                    "compression_needed": False,
                    "keyword_score": keyword_score,
                    "analysis": None
                }
                
        except Exception as e:
            print(f"ì£¼í–‰ ìƒí™© ê°ì§€ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ ì£¼í–‰ ì¤‘ì´ ì•„ë‹Œ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
            return {
                "is_driving": False,
                "confidence": 0.5,
                "driving_indicators": [],
                "urgency_level": "normal",
                "compression_needed": False,
                "keyword_score": 0.0,
                "analysis": None
            }
    
    def compress_answer(self, original_answer: str, query: str, urgency_level: str) -> Dict[str, Any]:
        """ì£¼í–‰ ì¤‘ ìƒí™©ì— ë§ê²Œ ë‹µë³€ ì••ì¶•"""
        try:
            # ì›ë³¸ ë‹µë³€ì—ì„œ ë¶ˆí•„ìš”í•œ ì •ë³´ ì œê±°
            cleaned_answer = self._clean_answer_for_driving(original_answer)
            
            # LLMì„ í†µí•œ ì§€ëŠ¥ì  ì••ì¶•
            compressed = self.compression_chain.invoke({
                "original_answer": cleaned_answer,
                "query": query,
                "urgency_level": urgency_level
            })
            
            # ìµœì¢… ì••ì¶• ë‹µë³€ ìƒì„±
            final_answer = self._format_compressed_answer(compressed, urgency_level)
            
            return {
                "compressed_answer": final_answer,
                "key_action": compressed.key_action,
                "safety_warning": compressed.safety_warning,
                "quick_steps": compressed.quick_steps,
                "follow_up": compressed.follow_up,
                "compression_ratio": len(final_answer) / len(original_answer)
            }
            
        except Exception as e:
            print(f"ë‹µë³€ ì••ì¶• ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê°„ë‹¨í•œ ì••ì¶• ì ìš©
            return {
                "compressed_answer": self._simple_compression(original_answer),
                "key_action": "ì›ë³¸ ë‹µë³€ ì°¸ì¡°",
                "safety_warning": "âš ï¸ ì•ˆì „í•œ ê³³ì—ì„œ ìƒì„¸ í™•ì¸ í•„ìš”",
                "quick_steps": [],
                "follow_up": "ì£¼í–‰ í›„ ë§¤ë‰´ì–¼ í™•ì¸",
                "compression_ratio": 0.3
            }
    
    def _calculate_keyword_score(self, query: str) -> float:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ì£¼í–‰ ìƒí™© ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        query_lower = query.lower()
        
        # ëª…ì‹œì  ì£¼í–‰ í‘œí˜„ (ê°€ì¤‘ì¹˜ ê°€ì¥ ë†’ìŒ)
        for pattern in self.driving_keywords["explicit"]:
            if re.search(pattern, query_lower):
                score += 0.4
        
        # ì‹œê°„ì  ê¸´ê¸‰ì„± í‘œí˜„
        for pattern in self.driving_keywords["temporal"]:
            if re.search(pattern, query_lower):
                score += 0.2
        
        # ìƒí™©ì  ë§¥ë½ í‘œí˜„
        for pattern in self.driving_keywords["situational"]:
            if re.search(pattern, query_lower):
                score += 0.1
        
        # ìœ„ì¹˜/ì´ë™ ê´€ë ¨ í‘œí˜„
        for pattern in self.driving_keywords["location"]:
            if re.search(pattern, query_lower):
                score += 0.15
        
        # ì°¨ëŸ‰ ìƒíƒœ/ë™ì‘ ê´€ë ¨ í‘œí˜„
        for pattern in self.driving_keywords["vehicle_state"]:
            if re.search(pattern, query_lower):
                score += 0.2
        
        # ìŒì„±/í•¸ì¦ˆí”„ë¦¬ ê´€ë ¨ í‘œí˜„
        for pattern in self.driving_keywords["audio_cues"]:
            if re.search(pattern, query_lower):
                score += 0.25
        
        # ì‘ê¸‰ ê³ ì¥ ìƒí™© (ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜)
        for pattern in self.driving_keywords["emergency_malfunction"]:
            if re.search(pattern, query_lower):
                score += 0.5  # ì‘ê¸‰ ê³ ì¥ì€ ë§¤ìš° ë†’ì€ ì ìˆ˜
        
        return min(score, 1.0)  # ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ
    
    def _clean_answer_for_driving(self, answer: str) -> str:
        """ì£¼í–‰ ì¤‘ ì••ì¶•ì„ ìœ„í•´ ë‹µë³€ì—ì„œ ë¶ˆí•„ìš”í•œ ì •ë³´ ì œê±°"""
        # ì œê±°í•  íŒ¨í„´ë“¤
        patterns_to_remove = [
            r'ğŸ“š\s*ì°¸ê³ \s*í˜ì´ì§€[:\s]*[\d\-,\s]+',  # í˜ì´ì§€ ì°¸ì¡°
            r'ğŸ”\s*\*\*ë‹µë³€\s*ì‹ ë¢°ë„\*\*[^ğŸ”]*',    # ì‹ ë¢°ë„ ì •ë³´
            r'âœ…\s*ë†’ì€\s*ì‹ ë¢°ë„[^âš ï¸âŒ]*',          # ì‹ ë¢°ë„ ë©”ì‹œì§€
            r'âš ï¸\s*ì¶”ê°€\s*í™•ì¸[^âŒ]*',              # ì¶”ê°€ í™•ì¸ ì•ˆë‚´
            r'âŒ\s*ì „ë¬¸ê°€\s*ìƒë‹´[^ğŸ“]*',            # ì „ë¬¸ê°€ ìƒë‹´ ì•ˆë‚´
            r'ğŸ“\s*\*\*ì¼ë°˜\s*ì§ˆë¬¸\*\*\s*\n\n',    # ì¼ë°˜ ì§ˆë¬¸ í—¤ë”
        ]
        
        cleaned = answer
        for pattern in patterns_to_remove:
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE | re.DOTALL)
        
        # ì—°ì†ëœ ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì •ë¦¬
        cleaned = re.sub(r'\n\s*\n', '\n', cleaned)
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        
        return cleaned
    
    def _format_compressed_answer(self, compressed: CompressedAnswer, urgency_level: str) -> str:
        """ì••ì¶•ëœ ë‹µë³€ì„ ìµœì¢… í˜•íƒœë¡œ í¬ë§·íŒ…"""
        if urgency_level == "immediate":
            # ì¦‰ì‹œ ëŒ€ì‘ - ìµœì†Œí•œì˜ ì •ë³´ë§Œ
            answer = f"ğŸš¨ {compressed.key_action}"
            if compressed.safety_warning:
                answer += f"\nâš ï¸ {compressed.safety_warning}"
            return answer
            
        elif urgency_level == "urgent":
            # ë¹ ë¥¸ ëŒ€ì‘ - í•µì‹¬ + ê°„ë‹¨ ë‹¨ê³„
            answer = f"âš¡ {compressed.key_action}"
            if compressed.quick_steps and len(compressed.quick_steps) <= 2:
                answer += "\n" + "\n".join([f"{i+1}. {step}" for i, step in enumerate(compressed.quick_steps[:2])])
            return answer
            
        else:
            # ì¼ë°˜ ìƒí™© - ìƒëŒ€ì ìœ¼ë¡œ ìƒì„¸
            answer = f"ğŸ“ {compressed.key_action}"
            if compressed.quick_steps:
                answer += "\n" + "\n".join([f"{i+1}. {step}" for i, step in enumerate(compressed.quick_steps[:3])])
            if compressed.follow_up:
                answer += f"\nğŸ“‹ ì£¼í–‰ í›„: {compressed.follow_up}"
            return answer
    
    def _simple_compression(self, answer: str) -> str:
        """ê°„ë‹¨í•œ ì••ì¶• (LLM ì‹¤íŒ¨ ì‹œ ë°±ì—…)"""
        # ì²« ë²ˆì§¸ ë¬¸ì¥ë§Œ ì¶”ì¶œ
        sentences = answer.split('.')
        if sentences:
            first_sentence = sentences[0].strip()
            if len(first_sentence) > 100:
                return first_sentence[:100] + "..."
            return first_sentence + "."
        return "âš ï¸ ì•ˆì „í•œ ê³³ì—ì„œ ìƒì„¸ í™•ì¸ í•„ìš”"
